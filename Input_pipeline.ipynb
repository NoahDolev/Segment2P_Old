{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessed submitted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure,color, img_as_int, img_as_ubyte\n",
    "from skimage.io import imread as pngread\n",
    "from skimage.io import imsave as pngsave\n",
    "from rolling_ball_filter import rolling_ball_filter\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters.rank import autolevel,equalize\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import sagemaker\n",
    "import boto3\n",
    "import shutil\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from sagemaker import get_execution_role\n",
    "from IPython.core.debugger import set_trace\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "# model_id = \"fresh-train-trial-2019-07-28-08-49-49-994\"\n",
    "# model_id = \"semantic-segmentatio-190726-1931-032-e7d26e04\"\n",
    "\n",
    "def preproc(img):\n",
    "    selem = disk(60)\n",
    "    try:\n",
    "        img = autolevel(img, selem)\n",
    "        img = exposure.adjust_gamma(img, 2)\n",
    "        img = cv2.bilateralFilter(img,9,75,75)\n",
    "    except:\n",
    "        print(img.shape)\n",
    "        pass\n",
    "    return(img)\n",
    "\n",
    "def createmultipleinputs(inputpath):\n",
    "    # pad to square\n",
    "    im = pngread(inputpath)\n",
    "    if len(im.shape)==3:\n",
    "        print('Images should be grayscale but had dimensions {} - automatically converted'.format(im.shape))\n",
    "        im = np.sum(im,2)\n",
    "    im = np.uint16(img_as_int(exposure.rescale_intensity(im, out_range=(0, 2**15 - 1))))\n",
    "    imshape =im.shape\n",
    "    edgediff = np.max(imshape)-np.min(imshape)\n",
    "    orig = im\n",
    "    if imshape[1]>imshape[0]:\n",
    "        orig = cv2.copyMakeBorder(im, math.ceil(edgediff/2), math.ceil(edgediff/2), 0, 0, cv2.BORDER_CONSTANT,value=[0,0,0])\n",
    "    if imshape[0]>imshape[1]:\n",
    "        orig = cv2.copyMakeBorder(im, 0, 0, math.ceil(edgediff/2), math.ceil(edgediff/2), cv2.BORDER_CONSTANT,value=[0,0,0])\n",
    "    \n",
    "    # ==>resize to 1024\n",
    "    im1024 = cv2.resize(orig, (1024,1024), interpolation = cv2.INTER_AREA)\n",
    "    # ==>resize to 720\n",
    "    im720 = cv2.resize(orig, (720,720), interpolation = cv2.INTER_AREA)\n",
    "    # preprocess both\n",
    "    im1024preproc = preproc(im1024)\n",
    "    im720preproc = preproc(im720)\n",
    "    return([orig, im1024preproc,im720preproc, im1024, im720])\n",
    "\n",
    "def populate_inputs(localpaths,batchid = ''):\n",
    "    os.makedirs('/tmp/{}/'.format(batchid), exist_ok=True)\n",
    "    imlabels = ['orig', 'im1024pp','im720pp','im1024','im720']\n",
    "    def innerloop(filepath,batchid = batchid, imlabels = imlabels):\n",
    "        resimages =  createmultipleinputs(filepath)\n",
    "        for idx in range(0,len(resimages)):\n",
    "            savepath = '/tmp/'+batchid+'/'+batchid+'_'+filepath.split('.')[0].split('/')[-1]+'__'+imlabels[idx]+'.jpg'\n",
    "            pngsave(savepath,resimages[idx])\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    Parallel(n_jobs=num_cores)(delayed(innerloop)(filepath) for filepath in localpaths)\n",
    "    os.system(\"aws s3 sync '/tmp/{}/' 's3://sagemaker-eu-west-1-102554356212/submissions/{}/' \".format(batchid,batchid))\n",
    "    shutil.rmtree('/tmp/{}/'.format(batchid))\n",
    "inputpath = '/home/ec2-user/SageMaker/itzik_images_cropped/'        \n",
    "files = os.listdir(inputpath)\n",
    "[os.rename(os.path.join(inputpath,f),os.path.join(inputpath,f.replace('_','-'))) for f in files]\n",
    "files = os.listdir(inputpath)\n",
    "files = [os.path.join(inputpath,f) for f in files if '.jpg' in f or '.png' in f or '.tif' in f] \n",
    "populate_inputs(files, batchid='itzik') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run batch job from a saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runbatch(model_id, batchid=''):\n",
    "    env = {'SAGEMAKER_MODEL_SERVER_TIMEOUT' : '3600' }\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    s3results = s3_resource.Bucket(name='sagemaker-eu-west-1-102554356212')\n",
    "    removesamples = [obj.key for obj in s3results.objects.all() if (\"results_\"+model_id in obj.key and batchid in obj.key and (\"out\" in obj.key or \"masks\" in obj.key))]\n",
    "    for removeme in removesamples:\n",
    "        boto3.client('s3').delete_object(Bucket = bucket, Key = removeme)\n",
    "\n",
    "    transform_job = sagemaker.transformer.Transformer(\n",
    "        model_name = model_id, \n",
    "        instance_count = 1,\n",
    "        instance_type = 'ml.p3.2xlarge',\n",
    "        strategy = 'SingleRecord',\n",
    "        assemble_with = 'None',\n",
    "        output_path = \"s3://sagemaker-eu-west-1-102554356212/results_{}/{}/\".format(model_id,batchid),\n",
    "        base_transform_job_name='inference-pipelines-batch',\n",
    "        sagemaker_session=sess,\n",
    "        accept = 'image/png',\n",
    "        env = env)\n",
    "    transform_job.transform(data = 's3://sagemaker-eu-west-1-102554356212/submissions/', \n",
    "                            content_type = 'image/jpeg', \n",
    "                            split_type = None)\n",
    "modelids = [\"fresh-train-trial-2019-07-28-08-49-49-994\", \"semantic-segmentatio-190726-1931-032-e7d26e04\"]\n",
    "[runbatch(model) for model in modelids]\n",
    "# transform_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read batch processed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_multiple_detections(masks):\n",
    "    \"\"\"\n",
    "\n",
    "    :param masks:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    IOU_THRESHOLD = 0.6\n",
    "    OVERLAP_THRESHOLD = 0.8\n",
    "    MIN_DETECTIONS = 1\n",
    "    def compute_iou(mask1, mask2):\n",
    "        \"\"\"\n",
    "        Computes Intersection over Union score for two binary masks.\n",
    "        :param mask1: numpy array\n",
    "        :param mask2: numpy array\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        intersection = np.sum((mask1 + mask2) > 1)\n",
    "        union = np.sum((mask1 + mask2) > 0)\n",
    "\n",
    "        return intersection / float(union)\n",
    "\n",
    "    def compute_overlap(mask1, mask2):\n",
    "        intersection = np.sum((mask1 + mask2) > 1)\n",
    "\n",
    "        overlap1 = intersection / float(np.sum(mask1))\n",
    "        overlap2 = intersection / float(np.sum(mask2))\n",
    "        return overlap1, overlap2\n",
    "\n",
    "    def sort_mask_by_cells(mask, min_size=50):\n",
    "        \"\"\"\n",
    "        Returns size of each cell.\n",
    "        :param mask:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        cell_num = np.unique(mask)\n",
    "        cell_sizes = [(cell_id, len(np.where(mask == cell_id)[0]))\n",
    "                      for cell_id in cell_num if cell_id != 0]\n",
    "\n",
    "        cell_sizes = [x for x in sorted(\n",
    "            cell_sizes, key=lambda x: x[1], reverse=True) if x[1 > min_size]]\n",
    "\n",
    "        return cell_sizes\n",
    "    \n",
    "    cell_counter = 0\n",
    "    final_mask = np.zeros(masks[0].shape)\n",
    "\n",
    "    masks_stats = [sort_mask_by_cells(mask) for mask in masks]\n",
    "    cells_left = sum([len(stats) for stats in masks_stats])\n",
    "\n",
    "    while cells_left > 0:\n",
    "        # Choose the biggest cell from available\n",
    "        cells = [stats[0][1] if len(\n",
    "            stats) > 0 else 0 for stats in masks_stats]\n",
    "        reference_mask = cells.index(max(cells))\n",
    "\n",
    "        reference_cell = masks_stats[reference_mask].pop(0)[0]\n",
    "\n",
    "        # Prepare binary mask for cell chosen for comparison\n",
    "        cell_location = np.where(masks[reference_mask] == reference_cell)\n",
    "\n",
    "        cell_mask = np.zeros(final_mask.shape)\n",
    "        cell_mask[cell_location] = 1\n",
    "\n",
    "        masks[reference_mask][cell_location] = 0\n",
    "\n",
    "        # Mask for storing temporary results\n",
    "        tmp_mask = np.zeros(final_mask.shape)\n",
    "        tmp_mask += cell_mask\n",
    "\n",
    "        for mask_id, mask in enumerate(masks):\n",
    "            # For each mask left\n",
    "            if mask_id != reference_mask:\n",
    "                # # Find overlapping cells on other masks\n",
    "                overlapping_cells = list(np.unique(mask[cell_location]))\n",
    "\n",
    "                try:\n",
    "                    overlapping_cells.remove(0)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "                # # If only one overlapping, check IoU and update tmp mask if high\n",
    "                if len(overlapping_cells) == 1:\n",
    "                    overlapping_cell_mask = np.zeros(final_mask.shape)\n",
    "                    overlapping_cell_mask[np.where(\n",
    "                        mask == overlapping_cells[0])] = 1\n",
    "\n",
    "                    iou = compute_iou(cell_mask, overlapping_cell_mask)\n",
    "                    if iou >= IOU_THRESHOLD:\n",
    "                        # Add cell to temporary results and remove from stats and mask\n",
    "                        tmp_mask += overlapping_cell_mask\n",
    "                        idx = [i for i, cell in enumerate(\n",
    "                            masks_stats[mask_id]) if cell[0] == overlapping_cells[0]][0]\n",
    "                        masks_stats[mask_id].pop(idx)\n",
    "                        mask[np.where(mask == overlapping_cells[0])] = 0\n",
    "\n",
    "                # # If more than one overlapping check area overlapping\n",
    "                elif len(overlapping_cells) > 1:\n",
    "                    overlapping_cell_masks = [\n",
    "                        np.zeros(final_mask.shape) for _ in overlapping_cells]\n",
    "\n",
    "                    for i, cell_id in enumerate(overlapping_cells):\n",
    "                        overlapping_cell_masks[i][np.where(\n",
    "                            mask == cell_id)] = 1\n",
    "\n",
    "                    for cell_id, overlap_mask in zip(overlapping_cells, overlapping_cell_masks):\n",
    "                        overlap_score, _ = compute_overlap(\n",
    "                            overlap_mask, cell_mask)\n",
    "\n",
    "                        if overlap_score >= OVERLAP_THRESHOLD:\n",
    "                            tmp_mask += overlap_mask\n",
    "\n",
    "                            mask[np.where(mask == cell_id)] = 0\n",
    "                            idx = [i for i, cell in enumerate(masks_stats[mask_id])\n",
    "                                   if cell[0] == cell_id][0]\n",
    "                            masks_stats[mask_id].pop(idx)\n",
    "\n",
    "                # # If none overlapping do nothing\n",
    "\n",
    "        if len(np.unique(tmp_mask)) > 1:\n",
    "            cell_counter += 1\n",
    "            final_mask[np.where(tmp_mask >= MIN_DETECTIONS)] = cell_counter\n",
    "\n",
    "        cells_left = sum([len(stats) for stats in masks_stats])\n",
    "\n",
    "    bin_mask = np.zeros(final_mask.shape)\n",
    "    bin_mask[np.where(final_mask > 0)] = 255\n",
    "    return(final_mask)\n",
    "\n",
    "def merge_two_masks(maskpaths):\n",
    "    masks = []\n",
    "    for mpath in maskpaths:\n",
    "        binarymask = pngread(mpath)\n",
    "        num_classes = 2\n",
    "        distance = ndi.distance_transform_edt(binarymask)\n",
    "        local_maxi = peak_local_max(distance, labels=binarymask, footprint=np.ones((3, 3)), indices=False)\n",
    "        markers = ndi.label(local_maxi)[0]\n",
    "        masks.append(watershed(-distance, markers, mask=binarymask))\n",
    "    mask = merge_multiple_detections(masks)\n",
    "    return(mask)\n",
    "\n",
    "def merge_masks(modelres, batchid = ''):\n",
    "    outpath  = '/tmp/results/{}/merged/'.format(batchid)\n",
    "    os.makedirs(outpath, exist_ok=True)\n",
    "    def savemerge(masklist, outpath = outpath, modelids = modelids):\n",
    "        mask = np.uint8(merge_two_masks(masklist))>0\n",
    "        savepath = os.path.join(outpath,'merged_'+masklist[0].split('/')[-1].split(modelids[0])[-1])\n",
    "        pngsave(savepath,mask)\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    Parallel(n_jobs=num_cores)(delayed(savemerge)([modelres[0][idx],modelres[1][idx]]) for idx in range(0,len(modelres[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Download data from batch job\n",
    "import boto3\n",
    "import mxnet as mx\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "from skimage.io import imread as pngread\n",
    "from skimage.io import imsave as pngsave\n",
    "\n",
    "batchid = 'itzik'\n",
    "\n",
    "def batch2masks(model_id, batchid = ''):\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    s3results = s3_resource.Bucket(name='sagemaker-eu-west-1-102554356212')\n",
    "    keys = [obj.key for obj in s3results.objects.all()]\n",
    "    os.makedirs('/tmp/results/{}'.format(batchid), exist_ok=True)\n",
    "    savepaths = []\n",
    "    for s3_object in keys:\n",
    "        if \"results_\"+model_id in s3_object and \"out\" in s3_object:\n",
    "                s3.meta.client.download_file('sagemaker-eu-west-1-102554356212', s3_object, '/tmp/'+s3_object.split('/')[-1])\n",
    "                with open('/tmp/'+s3_object.split('/')[-1], 'rb') as image:\n",
    "                    img = image.read()    \n",
    "                    img = bytearray(img)\n",
    "                    mask = np.array(Image.open(io.BytesIO(img)))\n",
    "                savepath = '/tmp/results/'+batchid+'/'+model_id+'.'.join(s3_object.split('/')[-1].split('.')[:-1])\n",
    "                pngsave(savepath, mask)\n",
    "                os.remove('/tmp/'+s3_object.split('/')[-1])\n",
    "                savepaths.append(savepath)\n",
    "    return(savepaths)\n",
    "modelids = [\"fresh-train-trial-2019-07-28-08-49-49-994\", \"semantic-segmentatio-190726-1931-032-e7d26e04\"]\n",
    "results = [batch2masks(mid, batchid = batchid) for mid in modelids]\n",
    "twomods = list(set([r.split(modelids[0])[-1] for r in results[0]])&set([r.split(modelids[1])[-1] for r in results[1]]))\n",
    "firstfiles = [r for r in results[0] if r.split(modelids[0])[-1] in twomods]\n",
    "secondfiles = [r for r in results[1] if r.split(modelids[1])[-1] in twomods]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge multiple masks from different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very very slow, must parallelize this\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.color import label2rgb\n",
    "import threading\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "merge_masks((firstfiles,secondfiles), batchid = batchid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-09.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-1-06.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-1-03.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-05.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-06.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-02.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-1-12.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-1-14.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-1-07.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-04.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-1-09.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-1-10.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-1-02.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-07-ver2.jpg', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-07.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-03.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-1-11.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-01.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-14.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/.ipynb-checkpoints', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-1-08.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-1-04.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-11.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-1-01.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-12.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-1-13.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-1-.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-08.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-10.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-1-05.tif', '/home/ec2-user/SageMaker/itzik-images-cropped/-B37-543-2-13.tif']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ec2-user/SageMaker/Segment2P/input_pipeline.py\", line 321, in inputpipeline\n",
      "    tj[len(tj)].wait()\n"
     ]
    }
   ],
   "source": [
    "from input_pipeline import *\n",
    "inputpath = '/home/ec2-user/SageMaker/itzik-images-cropped/'        \n",
    "files = os.listdir(inputpath)\n",
    "files = [os.path.join(inputpath,f) for f in files]\n",
    "# [os.rename(os.path.join(inputpath,f),os.path.join(inputpath,f.replace('_','-'))) for f in files]\n",
    "# files = os.listdir(inputpath)\n",
    "# files = [os.path.join(inputpath,f) for f in files if '.jpg' in f or '.png' in f or '.tif' in f] \n",
    "bid = inputpipeline(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge multiple masks from different inputs (different pre-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from processfiles import *\n",
    "from scipy import ndimage as ndi\n",
    "import threading\n",
    "import concurrent.futures\n",
    "\n",
    "def merge_masks_diff_inputs(groupkeys, batchid = ''):\n",
    "    os.makedirs('/tmp/results/{}/inputmerged/'.format(batchid), exist_ok=True)\n",
    "    masks = []\n",
    "    for file in groupkeys:\n",
    "        binarymask = cv2.resize(pngread(file), (1024,1024), interpolation = cv2.INTER_AREA)\n",
    "        distance = ndi.distance_transform_edt(binarymask)\n",
    "        local_maxi = peak_local_max(distance, labels=binarymask, footprint=np.ones((3, 3)), indices=False)\n",
    "        markers = ndi.label(local_maxi)[0]\n",
    "        masks.append(watershed(-distance, markers, mask=binarymask)) \n",
    "        try:\n",
    "            binarymask = merge_two_masks(outpaths)\n",
    "            distance = ndi.distance_transform_edt(binarymask)\n",
    "            local_maxi = peak_local_max(distance, labels=binarymask, footprint=np.ones((3, 3)), indices=False)\n",
    "            markers = ndi.label(local_maxi)[0]\n",
    "        except:\n",
    "            mask = watershed(-distance, markers, mask=binarymask)\n",
    "            pass\n",
    "        savepath = os.path.join('/tmp/results/'+batchid+'/inputmerged/',file.split('/')[-1].split('__')[0].replace('merged_','inputmerged_')+'.jpg')\n",
    "        pngsave(savepath, np.uint8(mask>0))\n",
    "batchid = 'itzik'\n",
    "keys = []\n",
    "for root, dirnames, filenames in os.walk('/tmp/results/{}/merged/'.format(batchid)):\n",
    "    for files in filenames:\n",
    "        if ('.jpg' in files or '.png' in files or '.tif' in files):\n",
    "            keys.append(os.path.join('/tmp/results/{}/merged/'.format(batchid),files))\n",
    "df = pd.DataFrame({'keys':keys,'orig_name':[k.split('/')[-1].split('__')[0].split('.jpg')[0] for k in keys]}) #add change file names if they have __\n",
    "originals = np.unique(df['orig_name'].values)\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "Parallel(n_jobs=num_cores)(delayed(merge_masks_diff_inputs)(df['keys'].loc[df['orig_name']==org].values, batchid) for org in originals)\n",
    "os.system(\"aws s3 sync '/tmp/results/{}/inputmerged/' 's3://sagemaker-eu-west-1-102554356212/results_merged/{}/' \".format(batchid,batchid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Input Pipeline (for inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "def randomString(stringLength=10):\n",
    "    \"\"\"Generate a random string of fixed length \"\"\"\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(stringLength))\n",
    "\n",
    "# def submitimages(input_dir_path,batchid = randomString(10)):\n",
    "\n",
    "input_dir_path = \"/home/ec2-user/SageMaker/itzik_images_cropped/\"\n",
    "for filename in os.listdir(input_dir_path): \n",
    "    os.rename(filename,filename.replace('_','-'))\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3results = s3_resource.Bucket(name='sagemaker-eu-west-1-102554356212')\n",
    "#create different inputs\n",
    "files = os.listdir(input_dir_path)\n",
    "files = [os.path.join(inputpath,f) for f in files if '.jpg' in f or '.png' in f or '.tif' in f]        \n",
    "populate_inputs(files, batchid = batchid) \n",
    "#model1 - infer mask for all inputs\n",
    "runbatch(\"semantic-segmentatio-190726-1931-032-e7d26e04\", batchid = batchid)\n",
    "#model2 - infer mask for all inputs\n",
    "runbatch(\"fresh-train-trial-2019-07-28-08-49-49-994\", batchid = batchid)\n",
    "#merge masks from different models\n",
    "keys = [obj.key for obj in s3results.objects.all() if batchid in obj.key]\n",
    "for key in keys:\n",
    "    t = threading.Thread(target = merge_masks, args=(key,[\"fresh-train-trial-2019-07-28-08-49-49-994\",\"semantic-segmentatio-190726-1931-032-e7d26e04\"],batchid)).start()\n",
    "os.system(\"aws s3 sync '/tmp/results/{}/merge/merged/ 's3://sagemaker-eu-west-1-102554356212/results_merged/{}/masks/'\".format(batchid,batchid)\n",
    "#merge masks from different inputs\n",
    "keys = [obj.key for obj in s3results.objects.all() if ('results_merged' in obj.key and 'masks' in obj.key and batchid in obj.key)]\n",
    "df = pd.DataFrame({'keys':keys,'orig_name':[k.split('/')[-1].split('__')[1].split('.jpg')[0] for k in keys]})\n",
    "originals = np.unique(df['orig_name'].values)\n",
    "for org in originals: \n",
    "          merge_masks_diff_inputs(groupkeys = df['keys'].loc[df['orig_name']==org].values,batchid = batchid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
