{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade pip\n",
    "!pip3 install --upgrade pip\n",
    "!pip install opencv-rolling-ball\n",
    "!pip install tifffile\n",
    "!pip install tifffile --user\n",
    "!pip3 install tifffile\n",
    "!pip3 install tifffile --user\n",
    "!sudo python3 -m pip install tifffile\n",
    "import sys\n",
    "sys.path.append('/home/ec2-user/.local/bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::102554356212:role/service-role/AmazonSageMaker-ExecutionRole-20181129T100657\n",
      "CPU times: user 1.54 s, sys: 640 ms, total: 2.18 s\n",
      "Wall time: 967 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from IPython.core.debugger import set_trace\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-eu-west-1-102554356212\n"
     ]
    }
   ],
   "source": [
    "bucket = sess.default_bucket()  \n",
    "prefix = 'fresh_train_trial'\n",
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "train_annotation_channel = prefix + '/train_annotation'\n",
    "validation_annotation_channel = prefix + '/validation_annotation'\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685385470294.dkr.ecr.eu-west-1.amazonaws.com/semantic-segmentation:latest\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "training_image = get_image_uri(sess.boto_region_name, 'semantic-segmentation', repo_version=\"latest\")\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from ImageJ: preprocessing\n",
    "# dir = getDirectory(\"Choose a Directory \");\n",
    "#    setBatchMode(true);\n",
    "#    count = 0;\n",
    "#    countFiles(dir);\n",
    "#    n = 0;\n",
    "#    processFiles(dir);\n",
    "#    //print(count+\" files processed\");\n",
    "   \n",
    "#    function countFiles(dir) {\n",
    "#       list = getFileList(dir);\n",
    "#       for (i=0; i<list.length; i++) {\n",
    "#           if (endsWith(list[i], \"/\"))\n",
    "#               countFiles(\"\"+dir+list[i]);\n",
    "#           else\n",
    "#               count++;\n",
    "#       }\n",
    "#   }\n",
    "\n",
    "#    function processFiles(dir) {\n",
    "#       list = getFileList(dir);\n",
    "#       for (i=0; i<list.length; i++) {\n",
    "#           if (endsWith(list[i], \"/\"))\n",
    "#               processFiles(\"\"+dir+list[i]);\n",
    "#           else {\n",
    "#              showProgress(n++, count);\n",
    "#              path = dir+list[i];\n",
    "#              processFile(path);\n",
    "#           }\n",
    "#       }\n",
    "#   }\n",
    "\n",
    "#   function processFile(path) {\n",
    "#        if (endsWith(path, \"raw.tif\")) {\n",
    "#            open(path);\n",
    "#            //run(\"Invert\");\n",
    "# \t\t   run(\"16-bit\");\n",
    "#            run(\"Enhance Contrast...\", \"saturated=0.3 normalize equalize\");\n",
    "# \t\t   run(\"Subtract Background...\", \"rolling=50\");\n",
    "#            run(\"Size...\", \"width=1024 height=1024 average interpolation=Bilinear\");\n",
    "#            run(\"Gaussian Blur...\", \"sigma=3\");\n",
    "#            run(\"Sharpen\");\n",
    "#            save(path);\n",
    "#            close();\n",
    "#       }\n",
    "#   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Hela Cell Dataset Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Hela cell dataset\n",
    "import boto3\n",
    "import numpy as np\n",
    "from skimage import util \n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage import exposure,color, img_as_int\n",
    "from skimage.io import imread as pngread\n",
    "from skimage.io import imsave as pngsave\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from tifffile import imsave,imread\n",
    "import cv2\n",
    "from rolling_ball_filter import rolling_ball_filter\n",
    "import random\n",
    "import threading\n",
    "\n",
    "files = []\n",
    "s3 = boto3.resource('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3meadata = s3_resource.Bucket(name='meadata')\n",
    "#remember to upload files\n",
    "def proccesshelafiles(f, s3 = s3, sess = sess, bucket = bucket, prefix = prefix):\n",
    "    train_channel = prefix + '/train'\n",
    "    validation_channel = prefix + '/validation'\n",
    "    train_annotation_channel = prefix + '/train_annotation'\n",
    "    validation_annotation_channel = prefix + '/validation_annotation'\n",
    "    if 'jpg' in f:\n",
    "        file = f\n",
    "        if 'segproj/hela_dataset_training_data/train/' in f:\n",
    "            jpgpath = '/tmp/'+'hela_'+file.split('/')[-1].split('.')[0]+'_'+'raw.jpg'\n",
    "            s3.meta.client.download_file('meadata', file, jpgpath)\n",
    "            inverted_img = pngread(jpgpath)\n",
    "            num = int(''.join(filter(str.isdigit, str(inverted_img.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(inverted_img, out_range=(0, 2**num - 1))\n",
    "            image =  cv2.resize(image, (1024,1024), interpolation = cv2.INTER_AREA) \n",
    "            pngsave(jpgpath,img_as_ubyte(image))\n",
    "            sess.upload_data(path=jpgpath, bucket=bucket, key_prefix=train_channel)\n",
    "        elif 'segproj/hela_dataset_training_data/val/' in f:\n",
    "            jpgpath = '/tmp/'+'hela_'+file.split('/')[-1].split('.')[0]+'_'+'raw.jpg'\n",
    "            s3.meta.client.download_file('meadata', file, jpgpath)\n",
    "            inverted_img = pngread(jpgpath)\n",
    "            num = int(''.join(filter(str.isdigit, str(inverted_img.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(inverted_img, out_range=(0, 2**num - 1))\n",
    "            image =  cv2.resize(image, (1024,1024), interpolation = cv2.INTER_AREA) \n",
    "            pngsave(jpgpath,img_as_ubyte(image))\n",
    "            sess.upload_data(path=jpgpath, bucket=bucket, key_prefix=validation_channel)\n",
    "    elif 'png' in f:\n",
    "        file = f\n",
    "        if 'segproj/hela_dataset_training_data/train_annotation/' in f:\n",
    "            pngpath = '/tmp/'+'hela_'+file.split('/')[-1].split('.')[0]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath)\n",
    "            im1 = pngread(pngpath)\n",
    "            num = int(''.join(filter(str.isdigit, str(im1.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(im1, out_range=(0, 2**num - 1))\n",
    "            image = img_as_ubyte(image)\n",
    "            im = mark_boundaries(image, im1, color = [0,0,0], outline_color = [0,0,0], mode='outer', background_label=0)\n",
    "            im2 = img_as_int(im)\n",
    "            im3 = np.zeros([im2.shape[0],im2.shape[1]])\n",
    "            im3 = im2[:,:,0]+im2[:,:,1]+im2[:,:,2]\n",
    "            im3 = np.uint8((im3>0))\n",
    "            im3 =  cv2.resize(im3, (1024,1024), interpolation = cv2.INTER_AREA)                 \n",
    "            pngsave(pngpath,im3, check_contrast=False)            \n",
    "            sess.upload_data(path=pngpath, bucket=bucket, key_prefix=train_annotation_channel)\n",
    "        elif 'segproj/hela_dataset_training_data/val_annotation/' in f:\n",
    "            pngpath = '/tmp/'+'hela_'+file.split('/')[-1].split('.')[0]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath)\n",
    "            im1 = pngread(pngpath)\n",
    "            num = int(''.join(filter(str.isdigit, str(im1.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(im1, out_range=(0, 2**num - 1))\n",
    "            image = img_as_ubyte(image)\n",
    "            im = mark_boundaries(image, im1, color = [0,0,0], outline_color = [0,0,0], mode='outer', background_label=0)\n",
    "            im2 = img_as_int(im)\n",
    "            im3 = np.zeros([im2.shape[0],im2.shape[1]])\n",
    "            im3 = im2[:,:,0]+im2[:,:,1]+im2[:,:,2]\n",
    "            im3 = np.uint8((im3>0))\n",
    "            im3 =  cv2.resize(im3, (1024,1024), interpolation = cv2.INTER_AREA)                 \n",
    "            pngsave(pngpath,im3, check_contrast=False)            \n",
    "            sess.upload_data(path=pngpath, bucket=bucket, key_prefix=validation_annotation_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Figure8 Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#figure8\n",
    "import boto3\n",
    "import numpy as np\n",
    "from skimage import util \n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage import exposure,color, img_as_int\n",
    "from skimage.io import imread as pngread\n",
    "from skimage.io import imsave as pngsave\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from tifffile import imsave,imread\n",
    "import cv2\n",
    "from rolling_ball_filter import rolling_ball_filter\n",
    "import random\n",
    "import threading\n",
    "\n",
    "files = []\n",
    "s3 = boto3.resource('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3meadata = s3_resource.Bucket(name='meadata')\n",
    "\n",
    "def proccessfigure8files(f, s3 = s3, sess = sess, bucket = bucket, prefix = prefix):\n",
    "    train_channel = prefix + '/train'\n",
    "    validation_channel = prefix + '/validation'\n",
    "    train_annotation_channel = prefix + '/train_annotation'\n",
    "    validation_annotation_channel = prefix + '/validation_annotation'\n",
    "    if 'tif' in f:\n",
    "        file = f\n",
    "        if 'segproj/training_data/train/' in f:\n",
    "            jpgpath = '/tmp/'+'fig8_raw_'+file.split('/')[-2]+'_'+'raw.jpg'\n",
    "            s3.meta.client.download_file('meadata', file, jpgpath.replace('jpg','tif'))\n",
    "            inverted_img = imread(jpgpath.replace('jpg','tif'))\n",
    "            num = int(''.join(filter(str.isdigit, str(inverted_img.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(inverted_img, out_range=(2**num - 1, 0))\n",
    "#             image = util.invert(image)\n",
    "            imsave(jpgpath,img_as_ubyte(image))\n",
    "            sess.upload_data(path=jpgpath, bucket=bucket, key_prefix=train_channel)\n",
    "        elif 'segproj/training_data/val/' in f:\n",
    "            jpgpath = '/tmp/'+'fig8_raw_'+file.split('/')[-2]+'_'+'raw.jpg'\n",
    "            s3.meta.client.download_file('meadata', file, jpgpath.replace('jpg','tif'))\n",
    "            inverted_img = imread(jpgpath.replace('jpg','tif'))\n",
    "            num = int(''.join(filter(str.isdigit, str(inverted_img.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(inverted_img, out_range=(2**num - 1, 0))\n",
    "#             image = util.invert(image)\n",
    "            imsave(jpgpath,img_as_ubyte(image))\n",
    "            sess.upload_data(path=jpgpath, bucket=bucket, key_prefix=validation_channel)\n",
    "    elif 'instances_ids.png' in f:\n",
    "        file = f\n",
    "        if 'segproj/training_data/train/' in f:\n",
    "            pngpath = '/tmp/'+'fig8_raw_'+file.split('/')[-2]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath)\n",
    "            im1 = pngread(pngpath)\n",
    "            num = int(''.join(filter(str.isdigit, str(im1.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(im1, out_range=(0, 2**num - 1))\n",
    "            image = img_as_ubyte(image)\n",
    "            im = mark_boundaries(image, im1, color = [0,0,0], outline_color = [0,0,0], mode='outer', background_label=0)\n",
    "            im2 = img_as_int(im)\n",
    "            im3 = np.zeros([im2.shape[0],im2.shape[1]])\n",
    "            im3 = im2[:,:,0]+im2[:,:,1]+im2[:,:,2]\n",
    "            im3 = np.uint8((im3>0))\n",
    "            im3 =  cv2.resize(im3, (1024,1024), interpolation = cv2.INTER_AREA)                 \n",
    "            pngsave(pngpath,im3, check_contrast=False)            \n",
    "            sess.upload_data(path=pngpath, bucket=bucket, key_prefix=train_annotation_channel)\n",
    "        elif 'segproj/training_data/val/' in f:\n",
    "            pngpath = '/tmp/'+'fig8_raw_'+file.split('/')[-2]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath)\n",
    "            im1 = pngread(pngpath)\n",
    "            num = int(''.join(filter(str.isdigit, str(im1.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(im1, out_range=(0, 2**num - 1))\n",
    "            image = img_as_ubyte(image)\n",
    "            im = mark_boundaries(image, im1, color = [0,0,0], outline_color = [0,0,0], mode='outer', background_label=0)\n",
    "            im2 = img_as_int(im)\n",
    "            im3 = np.zeros([im2.shape[0],im2.shape[1]])\n",
    "            im3 = im2[:,:,0]+im2[:,:,1]+im2[:,:,2]\n",
    "            im3 = np.uint8((im3>0))\n",
    "            im3 =  cv2.resize(im3, (1024,1024), interpolation = cv2.INTER_AREA)                 \n",
    "            pngsave(pngpath,im3, check_contrast=False)            \n",
    "            sess.upload_data(path=pngpath, bucket=bucket, key_prefix=validation_annotation_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Usiigaci Ground Truth (phase contrast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#usiigaci\n",
    "import boto3\n",
    "import numpy as np\n",
    "from skimage import util \n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage import exposure\n",
    "from skimage.io import imread as pngread\n",
    "from skimage.io import imsave as pngsave\n",
    "from tifffile import imsave,imread\n",
    "import cv2\n",
    "from rolling_ball_filter import rolling_ball_filter\n",
    "import random\n",
    "import threading\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage import color\n",
    "files = []\n",
    "s3 = boto3.resource('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3meadata = s3_resource.Bucket(name='meadata')\n",
    "\n",
    "def proccessusiigacifiles(f, s3 = s3, sess = sess, bucket = bucket, prefix = prefix):\n",
    "    train_channel = prefix + '/train'\n",
    "    validation_channel = prefix + '/validation'\n",
    "    train_annotation_channel = prefix + '/train_annotation'\n",
    "    validation_annotation_channel = prefix + '/validation_annotation'\n",
    "    if 'tif' in f:\n",
    "        file = f\n",
    "        if 'segproj/usiigaci_train_data/train/' in f:\n",
    "            jpgpath = '/tmp/'+'usiigaci_'+file.split('/')[-2]+'_'+'raw.jpg'\n",
    "            s3.meta.client.download_file('meadata', file, jpgpath.replace('jpg','tif'))\n",
    "            inverted_img = util.invert(imread(jpgpath.replace('jpg','tif')))\n",
    "            num = int(''.join(filter(str.isdigit, str(inverted_img.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(inverted_img, out_range=(0, 2**num - 1))\n",
    "            image =  cv2.resize(img_as_ubyte(image), (1024,1024), interpolation = cv2.INTER_AREA)\n",
    "#             image,_ = rolling_ball_filter(image, ball_radius = 20, spacing = 1, top=False)\n",
    "            imsave(jpgpath,image)\n",
    "            sess.upload_data(path=jpgpath, bucket=bucket, key_prefix=train_channel)\n",
    "        elif 'segproj/usiigaci_train_data/val/' in f:\n",
    "            jpgpath = '/tmp/'+'usiigaci_'+file.split('/')[-2]+'_'+'raw.jpg'\n",
    "            s3.meta.client.download_file('meadata', file, jpgpath.replace('jpg','tif'))\n",
    "            inverted_img = util.invert(imread(jpgpath.replace('jpg','tif')))\n",
    "            num = int(''.join(filter(str.isdigit, str(inverted_img.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(inverted_img, out_range=(0, 2**num - 1))\n",
    "            image =  cv2.resize(img_as_ubyte(image), (1024,1024), interpolation = cv2.INTER_AREA)\n",
    "#             image,_ = rolling_ball_filter(image, ball_radius = 20, spacing = 1, top=False)\n",
    "            imsave(jpgpath,image)\n",
    "            sess.upload_data(path=jpgpath, bucket=bucket, key_prefix=validation_channel)\n",
    "    elif 'instances_ids.png' in f:\n",
    "        file = f\n",
    "        if 'segproj/usiigaci_train_data/train/' in f:\n",
    "            pngpath = '/tmp/'+'usiigaci_'+file.split('/')[-2]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath)\n",
    "            im1 = pngread(pngpath)\n",
    "            num = int(''.join(filter(str.isdigit, str(im1.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(im1, out_range=(0, 2**num - 1))\n",
    "            image = img_as_ubyte(image)\n",
    "            im = mark_boundaries(image, im1, color = [0,0,0], outline_color = [0,0,0], mode='outer', background_label=0)\n",
    "            im2 = img_as_int(im)\n",
    "            im3 = np.zeros([im2.shape[0],im2.shape[1]])\n",
    "            im3 = im2[:,:,0]+im2[:,:,1]+im2[:,:,2]\n",
    "            im3 = np.uint8((im3>0))\n",
    "            im3 =  cv2.resize(im3, (1024,1024), interpolation = cv2.INTER_AREA)                 \n",
    "            pngsave(pngpath,im3, check_contrast=False)\n",
    "            sess.upload_data(path=pngpath, bucket=bucket, key_prefix=train_annotation_channel)\n",
    "        elif 'segproj/usiigaci_train_data/val/' in f:\n",
    "            pngpath = '/tmp/'+'usiigaci_'+file.split('/')[-2]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath)\n",
    "            im1 = pngread(pngpath)\n",
    "            num = int(''.join(filter(str.isdigit, str(im1.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(im1, out_range=(0, 2**num - 1))\n",
    "            image = img_as_ubyte(image)\n",
    "            im = mark_boundaries(image, im1, color = [0,0,0], outline_color = [0,0,0], mode='outer', background_label=0)\n",
    "            im2 = img_as_int(im)\n",
    "            im3 = np.zeros([im2.shape[0],im2.shape[1]])\n",
    "            im3 = im2[:,:,0]+im2[:,:,1]+im2[:,:,2]\n",
    "            im3 = np.uint8((im3>0))\n",
    "            im3 =  cv2.resize(im3, (1024,1024), interpolation = cv2.INTER_AREA)                 \n",
    "            pngsave(pngpath,im3, check_contrast=False)\n",
    "            sess.upload_data(path=pngpath, bucket=bucket, key_prefix=validation_annotation_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Lior's Ground Truth (manually adjusted MaskRCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "def proccessliorfiles(f, s3 = s3, sess = sess, bucket = bucket, prefix = prefix):\n",
    "    train_channel = prefix + '/train'\n",
    "    validation_channel = prefix + '/validation'\n",
    "    train_annotation_channel = prefix + '/train_annotation'\n",
    "    validation_annotation_channel = prefix + '/validation_annotation'\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    if 'tif' in f:\n",
    "        file = f\n",
    "        file = file.replace('._','')\n",
    "        if 'segproj/liorp_training_data/train/' in f:\n",
    "            jpgpath = '/tmp/'+'liorp_raw_'+file.split('/')[-2]+'_'+'raw.jpg'\n",
    "            s3.meta.client.download_file('meadata', file, jpgpath.replace('jpg','tif'))\n",
    "            image = imread(jpgpath.replace('jpg','tif'))\n",
    "            inverted_img =  cv2.resize(image, (1024,1024), interpolation = cv2.INTER_AREA)\n",
    "            num = int(''.join(filter(str.isdigit, str(inverted_img.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(inverted_img, out_range=(0, 2**num - 1))\n",
    "            imsave(jpgpath,img_as_ubyte(image))\n",
    "            sess.upload_data(path=jpgpath, bucket=bucket, key_prefix=train_channel)\n",
    "        elif 'segproj/liorp_training_data/val/' in f:\n",
    "            jpgpath = '/tmp/'+'liorp_raw_'+file.split('/')[-2]+'_'+'raw.jpg'\n",
    "            s3.meta.client.download_file('meadata', file, jpgpath.replace('jpg','tif'))\n",
    "            image = imread(jpgpath.replace('jpg','tif'))\n",
    "            inverted_img =  cv2.resize(image, (1024,1024), interpolation = cv2.INTER_AREA)\n",
    "            num = int(''.join(filter(str.isdigit, str(inverted_img.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(inverted_img, out_range=(0, 2**num - 1))\n",
    "            imsave(jpgpath,img_as_ubyte(image))\n",
    "            sess.upload_data(path=jpgpath, bucket=bucket, key_prefix=validation_channel)\n",
    "    elif 'instances_ids.png' in f:\n",
    "        file = f\n",
    "        file = file.replace('._','')\n",
    "        if 'segproj/liorp_training_data/train/' in f:\n",
    "            pngpath = '/tmp/'+'liorp_raw_'+file.split('/')[-2]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath)\n",
    "            im1 = pngread(pngpath)\n",
    "            num = int(''.join(filter(str.isdigit, str(im1.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(im1, out_range=(0, 2**num - 1))\n",
    "            image = img_as_ubyte(image)\n",
    "            im = mark_boundaries(image, im1, color = [0,0,0], outline_color = [0,0,0], mode='outer', background_label=0)\n",
    "            im2 = img_as_int(im)\n",
    "            im3 = np.zeros([im2.shape[0],im2.shape[1]])\n",
    "            im3 = im2[:,:,0]+im2[:,:,1]+im2[:,:,2]\n",
    "            im3 = np.uint8((im3>0))\n",
    "            im3 =  cv2.resize(im3, (1024,1024), interpolation = cv2.INTER_AREA)                 \n",
    "            pngsave(pngpath,im3, check_contrast=False)\n",
    "            sess.upload_data(path=pngpath, bucket=bucket, key_prefix=train_annotation_channel)\n",
    "        elif 'segproj/liorp_training_data/val/' in f:\n",
    "            pngpath = '/tmp/'+'liorp_raw_'+file.split('/')[-2]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath)\n",
    "            im1 = pngread(pngpath)\n",
    "            num = int(''.join(filter(str.isdigit, str(im1.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(im1, out_range=(0, 2**num - 1))\n",
    "            image = img_as_ubyte(image)\n",
    "            im = mark_boundaries(image, im1, color = [0,0,0], outline_color = [0,0,0], mode='outer', background_label=0)\n",
    "            im2 = img_as_int(im)\n",
    "            im3 = np.zeros([im2.shape[0],im2.shape[1]])\n",
    "            im3 = im2[:,:,0]+im2[:,:,1]+im2[:,:,2]\n",
    "            im3 = np.uint8((im3>0))\n",
    "            im3 =  cv2.resize(im3, (1024,1024), interpolation = cv2.INTER_AREA)                 \n",
    "            pngsave(pngpath,im3, check_contrast=False)\n",
    "            sess.upload_data(path=pngpath, bucket=bucket, key_prefix=validation_annotation_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add's filtered data to training set\n",
    "import boto3\n",
    "import numpy as np\n",
    "from skimage import util \n",
    "from skimage.util import img_as_ubyte,img_as_uint\n",
    "from skimage import exposure,color, img_as_int\n",
    "from skimage.io import imread \n",
    "from skimage.io import imsave\n",
    "from skimage.segmentation import mark_boundaries\n",
    "# from tifffile import imsave,imread\n",
    "import cv2\n",
    "from rolling_ball_filter import rolling_ball_filter\n",
    "import random\n",
    "import threading\n",
    "\n",
    "files = []\n",
    "s3 = boto3.resource('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3meadata = s3_resource.Bucket(name='meadata')\n",
    "\n",
    "def proccessfig8preprocfiles(f, s3 = s3, sess = sess, bucket = bucket, prefix = prefix):\n",
    "    train_channel = prefix + '/train'\n",
    "    validation_channel = prefix + '/validation'\n",
    "    train_annotation_channel = prefix + '/train_annotation'\n",
    "    validation_annotation_channel = prefix + '/validation_annotation'\n",
    "    if 'tif' in f:\n",
    "        file = f\n",
    "        if 'segproj/fig8_preprocessed/train/' in f:\n",
    "            pngpath = '/tmp/'+'fig8_'+file.split('/')[-2]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath.replace('png','tif'))\n",
    "            inverted_img = imread(pngpath.replace('png','tif'))\n",
    "            num = int(''.join(filter(str.isdigit, str(inverted_img.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(inverted_img, out_range=(0,2**8 - 1))\n",
    "            cv2.imwrite(pngpath.replace('png','jpg'),img_as_ubyte(image),[int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "            sess.upload_data(path=pngpath.replace('png','jpg'), bucket=bucket, key_prefix=train_channel)\n",
    "        elif 'segproj/fig8_preprocessed/val/' in f:\n",
    "            pngpath = '/tmp/'+'fig8_'+file.split('/')[-2]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath.replace('png','tif'))\n",
    "            inverted_img = imread(pngpath.replace('png','tif'))\n",
    "            num = int(''.join(filter(str.isdigit, str(inverted_img.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(inverted_img, out_range=(0,2**8 - 1))\n",
    "            cv2.imwrite(pngpath.replace('png','jpg'),img_as_ubyte(image),[int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "            sess.upload_data(path=pngpath.replace('png','jpg'), bucket=bucket, key_prefix=validation_channel)\n",
    "    elif 'instances_ids.png' in f:\n",
    "        file = f\n",
    "        if 'segproj/fig8_preprocessed/train/' in f:\n",
    "            pngpath = '/tmp/'+'fig8_'+file.split('/')[-2]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath)\n",
    "            im1 = imread(pngpath)\n",
    "            num = int(''.join(filter(str.isdigit, str(im1.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(im1, out_range=(0, 2**num - 1))\n",
    "            image = img_as_ubyte(image)\n",
    "            im = mark_boundaries(image, im1, color = [0,0,0], outline_color = [0,0,0], mode='outer', background_label=0)\n",
    "            im2 = img_as_int(im)\n",
    "            im3 = np.zeros([im2.shape[0],im2.shape[1]])\n",
    "            im3 = im2[:,:,0]+im2[:,:,1]+im2[:,:,2]\n",
    "            im3 = np.uint8((im3>0))\n",
    "            im3 =  cv2.resize(im3, (1024,1024), interpolation = cv2.INTER_AREA)                 \n",
    "            cv2.imwrite(pngpath,im3,[int(cv2.IMWRITE_PNG_COMPRESSION), 0])          \n",
    "            sess.upload_data(path=pngpath, bucket=bucket, key_prefix=train_annotation_channel)\n",
    "        elif 'segproj/fig8_preprocessed/val/' in f:\n",
    "            pngpath = '/tmp/'+'fig8_'+file.split('/')[-2]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath)\n",
    "            im1 = imread(pngpath)\n",
    "            num = int(''.join(filter(str.isdigit, str(im1.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(im1, out_range=(0, 2**num - 1))\n",
    "            image = img_as_ubyte(image)\n",
    "            im = mark_boundaries(image, im1, color = [0,0,0], outline_color = [0,0,0], mode='outer', background_label=0)\n",
    "            im2 = img_as_int(im)\n",
    "            im3 = np.zeros([im2.shape[0],im2.shape[1]])\n",
    "            im3 = im2[:,:,0]+im2[:,:,1]+im2[:,:,2]\n",
    "            im3 = np.uint8((im3>0))\n",
    "            im3 =  cv2.resize(im3, (1024,1024), interpolation = cv2.INTER_AREA)                 \n",
    "            cv2.imwrite(pngpath,im3,[int(cv2.IMWRITE_PNG_COMPRESSION), 0])            \n",
    "            sess.upload_data(path=pngpath, bucket=bucket, key_prefix=validation_annotation_channel)\n",
    "\n",
    "def proccessliorpreprocfiles(f, s3 = s3, sess = sess, bucket = bucket, prefix = prefix):\n",
    "    train_channel = prefix + '/train'\n",
    "    validation_channel = prefix + '/validation'\n",
    "    train_annotation_channel = prefix + '/train_annotation'\n",
    "    validation_annotation_channel = prefix + '/validation_annotation'\n",
    "    if 'tif' in f:\n",
    "        file = f\n",
    "        file = file.replace('._','')\n",
    "        if 'segproj/liorp_preprocessed/train/' in f:\n",
    "            pngpath = '/tmp/'+'liorp_'+file.split('/')[-2]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath.replace('png','tif'))\n",
    "            image = imread(pngpath.replace('png','tif'))\n",
    "            inverted_img =  cv2.resize(image, (1024,1024), interpolation = cv2.INTER_AREA)\n",
    "            num = int(''.join(filter(str.isdigit, str(inverted_img.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(inverted_img, out_range=(0, 2**8 - 1))\n",
    "            cv2.imwrite(pngpath.replace('png','jpg'),img_as_ubyte(image),[int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "            sess.upload_data(path=pngpath.replace('png','jpg'), bucket=bucket, key_prefix=train_channel)\n",
    "        elif 'segproj/liorp_preprocessed/val/' in f:\n",
    "            pngpath = '/tmp/'+'liorp_'+file.split('/')[-2]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath.replace('png','tif'))\n",
    "            image = imread(pngpath.replace('png','tif'))\n",
    "            inverted_img =  cv2.resize(image, (1024,1024), interpolation = cv2.INTER_AREA)\n",
    "            num = int(''.join(filter(str.isdigit, str(inverted_img.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(inverted_img, out_range=(0, 2**8 - 1))\n",
    "            cv2.imwrite(pngpath.replace('png','jpg'),img_as_ubyte(image),[int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "            sess.upload_data(path=pngpath.replace('png','jpg'), bucket=bucket, key_prefix=validation_channel)\n",
    "    elif 'instances_ids.png' in f:\n",
    "        file = f\n",
    "        file = file.replace('._','')\n",
    "        if 'segproj/liorp_preprocessed/train/' in f:\n",
    "            pngpath = '/tmp/'+'liorp_'+file.split('/')[-2]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath)\n",
    "            im1 = imread(pngpath)\n",
    "            num = int(''.join(filter(str.isdigit, str(im1.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(im1, out_range=(0, 2**num - 1))\n",
    "            image = img_as_ubyte(image)\n",
    "            im = mark_boundaries(image, im1, color = [0,0,0], outline_color = [0,0,0], mode='outer', background_label=0)\n",
    "            im2 = img_as_int(im)\n",
    "            im3 = np.zeros([im2.shape[0],im2.shape[1]])\n",
    "            im3 = im2[:,:,0]+im2[:,:,1]+im2[:,:,2]\n",
    "            im3 = np.uint8((im3>0))\n",
    "            im3 =  cv2.resize(im3, (1024,1024), interpolation = cv2.INTER_AREA)                 \n",
    "            cv2.imwrite(pngpath,im3,[int(cv2.IMWRITE_PNG_COMPRESSION), 0])\n",
    "            sess.upload_data(path=pngpath, bucket=bucket, key_prefix=train_annotation_channel)\n",
    "        elif 'segproj/liorp_preprocessed/val/' in f:\n",
    "            pngpath = '/tmp/'+'liorp_'+file.split('/')[-2]+'_'+'raw.png'\n",
    "            s3.meta.client.download_file('meadata', file, pngpath)\n",
    "            im1 = imread(pngpath)\n",
    "            num = int(''.join(filter(str.isdigit, str(im1.dtype)))) - 1\n",
    "            image = exposure.rescale_intensity(im1, out_range=(0, 2**num - 1))\n",
    "            image = img_as_ubyte(image)\n",
    "            im = mark_boundaries(image, im1, color = [0,0,0], outline_color = [0,0,0], mode='outer', background_label=0)\n",
    "            im2 = img_as_int(im)\n",
    "            im3 = np.zeros([im2.shape[0],im2.shape[1]])\n",
    "            im3 = im2[:,:,0]+im2[:,:,1]+im2[:,:,2]\n",
    "            im3 = np.uint8((im3>0))\n",
    "            im3 =  cv2.resize(im3, (1024,1024), interpolation = cv2.INTER_AREA)                 \n",
    "            cv2.imwrite(pngpath,im3,[int(cv2.IMWRITE_PNG_COMPRESSION), 0])\n",
    "            sess.upload_data(path=pngpath, bucket=bucket, key_prefix=validation_annotation_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run process functions (raw and filtered versions of fig8 and liorP)\n",
    "def procfilepar(key):\n",
    "    proccessliorpreprocfiles(key)\n",
    "    proccessliorfiles(key)\n",
    "    proccessfigure8files(key)\n",
    "    proccessfig8preprocfiles(key)\n",
    "keys = [obj.key for obj in s3meadata.objects.all()]\n",
    "for key in keys:\n",
    "    t = threading.Thread(target = procfilepar, args=(key,)).start()\n",
    "#     proccessliorpreprocfiles(key)\n",
    "#     proccessliorfiles(key)\n",
    "#     proccessfigure8files(key)\n",
    "#     proccessfig8preprocfiles(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop dataset images around labeled areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #still bugs here - sizes don't come out right. Some masks are 256 while images are 1024\n",
    "from math import floor\n",
    "import os\n",
    "\n",
    "def cropimage(image, best_box = None):\n",
    "    try:\n",
    "        imgray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    except:\n",
    "        print(image.shape)\n",
    "        imgray = image\n",
    "        pass\n",
    "    \n",
    "    if best_box is None:\n",
    "        ret,thresh = cv2.threshold(np.uint8(imgray>0),0,255,cv2.THRESH_BINARY_INV)\n",
    "        dilated=cv2.morphologyEx(thresh, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(10,10)))\n",
    "        contours,_ = cv2.findContours(dilated,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "        new_contours=[]\n",
    "        for c in contours:\n",
    "            if cv2.contourArea(c)<256*256:\n",
    "                new_contours.append(c)\n",
    "        best_box=[-1,-1,-1,-1]\n",
    "        for c in new_contours:\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            if best_box[0] < 0:\n",
    "                best_box=[x,y,x+w,y+h]\n",
    "            else:\n",
    "                if x<best_box[0]:\n",
    "                    best_box[0]=x\n",
    "                if y<best_box[1]:\n",
    "                    best_box[1]=y\n",
    "                if x+w>best_box[2]:\n",
    "                    best_box[2]=x+w\n",
    "                if y+h>best_box[3]:\n",
    "                    best_box[3]=y+h\n",
    "    if (np.abs(best_box[2]-best_box[0])>100)&(np.abs(best_box[3]-best_box[1])>100):\n",
    "        roi = imgray[best_box[1]:best_box[3], best_box[0]:best_box[2]]\n",
    "        roi = roi[0:np.min(roi.shape), 0:np.min(roi.shape)]\n",
    "    else:\n",
    "        print(best_box)\n",
    "        roi = imgray\n",
    "    roi =  cv2.resize(roi, (256,256), interpolation = cv2.INTER_AREA)\n",
    "    return(roi, best_box)\n",
    "\n",
    "def performcrop(key, bucket  = bucket, prefix = prefix ):\n",
    "    train_channel = prefix + '/train'\n",
    "    validation_channel = prefix + '/validation'\n",
    "    train_annotation_channel = prefix + '/train_annotation'\n",
    "    validation_annotation_channel = prefix + '/validation_annotation'\n",
    "    imsavepath = \"/tmp/\"+key.split('/')[-1]\n",
    "    maskkey = key.replace('train/',\"train_annotation/\").replace('val/','val_annotation/').replace('jpg','png')\n",
    "    masksavepath = \"/tmp/\"+maskkey.split('/')[-1]\n",
    "    try:\n",
    "        s3.meta.client.download_file(bucket, key, imsavepath)\n",
    "        s3.meta.client.download_file(bucket, maskkey , masksavepath)\n",
    "    except:\n",
    "        try:\n",
    "            s3.meta.client.delete_objects(bucket, key, imsavepath)\n",
    "            s3.meta.client.delete_objects(bucket, maskkey , masksavepath)\n",
    "        except:\n",
    "            pass\n",
    "        pass\n",
    "        \n",
    "    if os.stat(imsavepath).st_size > 2000:\n",
    "        mask,box = cropimage(cv2.imread(masksavepath))\n",
    "        im,_ = cropimage(cv2.imread(imsavepath), best_box = box)\n",
    "        cv2.imwrite(imsavepath,im)\n",
    "        cv2.imwrite(masksavepath,mask)\n",
    "        if 'train/' in key:\n",
    "            sess.upload_data(path=imsavepath, bucket=bucket, key_prefix=train_channel)\n",
    "            sess.upload_data(path=masksavepath, bucket=bucket, key_prefix=train_annotation_channel)\n",
    "        elif 'validation/' in key:\n",
    "            sess.upload_data(path=imsavepath, bucket=bucket, key_prefix=validation_channel)\n",
    "            sess.upload_data(path=masksavepath, bucket=bucket, key_prefix=validation_annotation_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [obj.key for obj in s3_resource.Bucket(name=bucket).objects.all() if ('jpg' in obj.key and prefix in obj.key)]\n",
    "for key in keys:\n",
    "#     performcrop(key)\n",
    "     t = threading.Thread(target = performcrop, args=(key,)).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "label_map = { \"scale\": 1 }\n",
    "with open('train_label_map.json', 'w') as lm_fname:\n",
    "    json.dump(label_map, lm_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-west-1-102554356212/fresh_train_trial/output\n"
     ]
    }
   ],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print(s3_output_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sagemaker estimator object.\n",
    "ss_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count = 1, \n",
    "                                         train_instance_type = 'ml.p3.16xlarge',\n",
    "                                         train_volume_size = 300, # size in gb on s3 to reserve\n",
    "                                         train_max_run = 360000,\n",
    "                                         output_path = s3_output_location,\n",
    "                                         base_job_name = 'fresh-train-trial',\n",
    "                                         sagemaker_session = sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup hyperparameters \n",
    "numtrain = len([obj.key for obj in s3meadata.objects.all() if ('train' in obj.key and 'jpg' in obj.key)])\n",
    "ss_model.set_hyperparameters(backbone='resnet-101', # This is the encoder. Other option is resnet-50\n",
    "                             algorithm='deeplab', # This is the decoder. Other option is 'psp' and 'deeplab'                             \n",
    "                             use_pretrained_model='False', # Use the pre-trained model.\n",
    "                             crop_size=240, # Size of image random crop.                             \n",
    "                             num_classes=2, # Background + cell \n",
    "                             epochs=1000, # Number of epochs to run.\n",
    "                             learning_rate=0.00058, momentum = 0.916, weight_decay = 0.000114,                           \n",
    "                             optimizer='adagrad', # Other options include 'adam', 'rmsprop', 'nag', 'adagrad'.\n",
    "                             lr_scheduler='poly', # Other options include 'cosine' and 'step'.                           \n",
    "                             mini_batch_size=41, # Setup some mini batch size.\n",
    "                             validation_mini_batch_size=16, #try larger batch sizes maybe? \n",
    "                             early_stopping=True, # Turn on early stopping. If OFF, other early stopping parameters are ignored.\n",
    "                             early_stopping_patience=50, # Tolerate these many epochs if the mIoU doens't increase.\n",
    "                             early_stopping_min_epochs=25, # No matter what, run these many number of epochs.                             \n",
    "                             num_training_samples=numtrain) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup data inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full bucket names\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)\n",
    "s3_train_annotation = 's3://{}/{}'.format(bucket, train_annotation_channel)\n",
    "s3_validation_annotation = 's3://{}/{}'.format(bucket, validation_annotation_channel)\n",
    "\n",
    "distribution = 'FullyReplicated'\n",
    "# Create sagemaker s3_input objects\n",
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution=distribution, \n",
    "                                        content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution=distribution, \n",
    "                                        content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "train_annotation = sagemaker.session.s3_input(s3_train_annotation, distribution=distribution, \n",
    "                                        content_type='image/png', s3_data_type='S3Prefix')\n",
    "validation_annotation = sagemaker.session.s3_input(s3_validation_annotation, distribution=distribution, \n",
    "                                        content_type='image/png', s3_data_type='S3Prefix')\n",
    "\n",
    "data_channels = {'train': train_data, \n",
    "                 'validation': validation_data,\n",
    "                 'train_annotation': train_annotation, \n",
    "                 'validation_annotation':validation_annotation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Hyperparameter Optimization (optionally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParam Optimization\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "paramdict = {'weight_decay': ContinuousParameter(0.0001, 0.5), \n",
    "             'optimizer': CategoricalParameter(['rmsprop','adam','nag', 'adagrad']),\n",
    "             'learning_rate': ContinuousParameter(0.0001, 0.1), \n",
    "             'momentum': ContinuousParameter(0.5, 1), \n",
    "             'mini_batch_size': IntegerParameter(8,96) }\n",
    "\n",
    "objective_metric_name = 'Validation-mIOU'\n",
    "metric_definitions = [{'Name': 'validation-mIOU',\n",
    "                       'Regex': 'validation mIOU=([0-9\\\\.]+)'}]\n",
    "\n",
    "tuner = HyperparameterTuner(ss_model,\n",
    "                            objective_metric_name = 'validation:mIOU',\n",
    "                            hyperparameter_ranges = paramdict,\n",
    "                            max_jobs=300,\n",
    "                            max_parallel_jobs=2)\n",
    "\n",
    "tuner.fit(inputs=data_channels)\n",
    "# # bayes_metrics = sagemaker.HyperparameterTuningJobAnalytics(tuner._current_job_name).dataframe()\n",
    "# # bayes_metrics.sort_values(['FinalObjectiveValue'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model and deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "ss_model.fit(inputs=data_channels, logs=True)\n",
    "ss_predictor = ss_model.deploy(initial_instance_count=1, instance_type='ml.c4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an image for segmenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import io\n",
    "import boto3\n",
    "import numpy as np\n",
    "from skimage import util \n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage import exposure\n",
    "from skimage.io import imread as pngread\n",
    "from skimage.io import imsave as pngsave\n",
    "from tifffile import imsave,imread\n",
    "import cv2\n",
    "from rolling_ball_filter import rolling_ball_filter\n",
    "import random\n",
    "import threading\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage import color\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(64,64))\n",
    "# images/liorp_181106_2_raw.jpg\n",
    "filename = \"/home/ec2-user/SageMaker/itzik_images_cropped/_B37-543-2_07_ver2.tif\"\n",
    "# filename = \"/home/ec2-user/SageMaker/images/190221_LV_ver2.tif\"\n",
    "im = imread(filename)\n",
    "# selem = disk(60)\n",
    "# inimage = rank.equalize(inimage, selem=selem)  \n",
    "# im = clahe.apply(im)\n",
    "# im,_ = rolling_ball_filter(im, ball_radius = 20, spacing = 1, top=False)\n",
    "im =  cv2.resize(im, (720,720), interpolation = cv2.INTER_AREA)\n",
    "num = int(''.join(filter(str.isdigit, str(im.dtype)))) - 1\n",
    "im = img_as_ubyte(exposure.rescale_intensity(im, out_range=(0, 2**num - 1)))\n",
    "pngsave(filename.replace('tif','jpg'), im)\n",
    "\n",
    "with open(filename.replace('tif','jpg'), 'rb') as image:\n",
    "    img = image.read()    \n",
    "    img = bytearray(img)\n",
    "\n",
    "fig1 = plt.figure(figsize=(10, 10)) # create a figure with the default size \n",
    "ax1 = fig1.add_subplot(1,1,1) \n",
    "ax1.imshow(Image.open(io.BytesIO(img)), interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "ss_predictor.content_type = 'image/jpeg'\n",
    "ss_predictor.accept = 'image/png'\n",
    "return_img = ss_predictor.predict(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us display the segmentation mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "import seaborn as sns\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "num_classes = 2\n",
    "mask = np.array(Image.open(io.BytesIO(return_img)))\n",
    "distance = ndi.distance_transform_edt(mask)\n",
    "local_maxi = peak_local_max(distance, labels=mask, footprint=np.ones((3, 3)), indices=False)\n",
    "markers = ndi.label(local_maxi)[0]\n",
    "labels = watershed(-distance, markers, mask=mask)\n",
    "pngsave('/home/ec2-user/SageMaker/testresult_mask.tif', mask)\n",
    "\n",
    "fig1 = plt.figure(figsize=(20, 20)) # create a figure with the default size \n",
    "ax1 = fig1.add_subplot(2,2,1) \n",
    "result = label2rgb(label = labels, image = exposure.rescale_intensity(im.astype(np.float), out_range=(-1, 1)))\n",
    "ax1.imshow(result)\n",
    "ax2 = fig1.add_subplot(2,2,2) \n",
    "ax2.imshow(labels)\n",
    "plt.show()\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(ss_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inference on deployed model \n",
    "### (new notebook run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from sagemaker.amazon.record_pb2 import Record\n",
    "import mxnet as mx\n",
    "from scipy import ndimage as ndi\n",
    "from PIL import Image\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "import seaborn as sns\n",
    "from skimage.color import label2rgb\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "endpoint = \"fresh-train-trial-2019-07-18-07-09-22-322\"\n",
    " \n",
    "runtime = boto3.Session().client('sagemaker-runtime')\n",
    " \n",
    "# Read image into memory\n",
    "# Send image via InvokeEndpoint API\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint, ContentType='image/jpeg', Accept = 'image/png', Body=img)\n",
    "return_img = response['Body'].read()\n",
    "num_classes = 2\n",
    "mask = np.array(Image.open(io.BytesIO(return_img)))\n",
    "distance = ndi.distance_transform_edt(mask)\n",
    "local_maxi = peak_local_max(distance, labels=mask, footprint=np.ones((3, 3)), indices=False)\n",
    "markers = ndi.label(local_maxi)[0]\n",
    "labels = watershed(-distance, markers, mask=mask)\n",
    "pngsave('/home/ec2-user/SageMaker/testresult_orig.png', exposure.rescale_intensity(im.astype(np.float), out_range=(-1, 1)))\n",
    "pngsave('/home/ec2-user/SageMaker/testresult_mask.png', mask)\n",
    "\n",
    "fig1 = plt.figure(figsize=(20, 20)) # create a figure with the default size \n",
    "ax1 = fig1.add_subplot(2,2,1) \n",
    "result = label2rgb(label = labels, image = exposure.rescale_intensity(im.astype(np.float), out_range=(-1, 1)))\n",
    "ax1.imshow(result)\n",
    "ax2 = fig1.add_subplot(2,2,2) \n",
    "ax2.imshow(labels)\n",
    "plt.show()\n",
    "np.unique(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a batch job from a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch Job\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from IPython.core.debugger import set_trace\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "transform_job = sagemaker.transformer.Transformer(\n",
    "    model_name = \"fresh-train-trial-2019-07-18-07-09-22-322\",\n",
    "    instance_count = 1,\n",
    "    instance_type = 'ml.m5.xlarge',\n",
    "    strategy = 'SingleRecord',\n",
    "    assemble_with = 'None',\n",
    "    output_path = \"s3://sagemaker-eu-west-1-102554356212/results/\",\n",
    "    base_transform_job_name='inference-pipelines-batch',\n",
    "    sagemaker_session=sess,\n",
    "    accept = 'image/png')\n",
    "transform_job.transform(data = 's3://sagemaker-eu-west-1-102554356212/submissions/' , \n",
    "                        content_type = 'image/png', \n",
    "                        split_type = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read batch processed results and export mask back to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from batch job\n",
    "import boto3\n",
    "import mxnet as mx\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "from skimage.io import imread as pngread\n",
    "from skimage.io import imsave as pngsave\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3results = s3_resource.Bucket(name='sagemaker-eu-west-1-102554356212')\n",
    "keys = [obj.key for obj in s3results.objects.all()]\n",
    "os.makedirs('/tmp/results/', exist_ok=True)\n",
    "for s3_object in keys:\n",
    "    if not s3_object.endswith(\"/\") and \"results\" in s3_object and \"out\" in s3_object:\n",
    "            s3.meta.client.download_file('sagemaker-eu-west-1-102554356212', s3_object, '/tmp/tempfile.out')\n",
    "            num_classes = 2\n",
    "            with open('/tmp/tempfile.out', 'rb') as image:\n",
    "                img = image.read()    \n",
    "                img = bytearray(img)\n",
    "                mask = np.array(Image.open(io.BytesIO(img)))\n",
    "                print('.'.join(s3_object.split('/')[-1].split('.')[:-1]))\n",
    "                pngsave('/tmp/results/'+'.'.join(s3_object.split('/')[-1].split('.')[:-1]), mask)\n",
    "!aws s3 sync '/tmp/results/' 's3://sagemaker-eu-west-1-102554356212/results/masks/'               "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
