{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:52:51.949187Z",
     "start_time": "2018-12-15T13:52:29.593597Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Segmentation Functions\n",
    "import sys\n",
    "sys.path.insert(0, '/home/ec2-user/SageMaker/Segment2P')\n",
    "\n",
    "from segment_functions import *\n",
    "#--------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/ec2-user/SageMaker/images/\"\n",
    "model_path_1 = \"/home/mestalbet/Segment2P/TrainWeights/mask_rcnn_cell_0100.h5\"\n",
    "model_path_2 = \"/home/mestalbet/Segment2P/TrainWeights/mask_rcnn_cell_0198.h5\"\n",
    "model_path_3 = \"/home/mestalbet/Segment2P/TrainWeights/mask_rcnn_cell_0199.h5\"\n",
    "model_path_4 = \"/home/mestalbet/Segment2P/TrainWeights/mask_rcnn_cell_0200.h5\"\n",
    "model_list = [model_path_1, model_path_2, model_path_3, model_path_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Configuration class\n",
    "chunksize = 1\n",
    "class CellInferenceConfig(cellConfig):\n",
    "        # Set batch size to 1 to run one image at a time\n",
    "        GPU_COUNT = 1\n",
    "        IMAGES_PER_GPU = chunksize\n",
    "        # Don't resize imager for inferencing\n",
    "        IMAGE_RESIZE_MODE = \"pad64\"\n",
    "        # Non-max suppression threshold to filter RPN proposals.\n",
    "        # You can increase this during training to generate more propsals.\n",
    "        RPN_NMS_THRESHOLD = 0.7\n",
    "        # define the folder path to data for prediction\n",
    "        global data_dir\n",
    "        all_files = []\n",
    "        sub_directory = []\n",
    "        for root, dirs, files in os.walk(data_dir):\n",
    "            for file in files:\n",
    "                relativePath = os.path.relpath(root, data_dir)\n",
    "                if relativePath == \".\":\n",
    "                    relativePath = \"\"\n",
    "                all_files.append(\n",
    "                    (relativePath.count(os.path.sep), relativePath, file))\n",
    "        all_files.sort(reverse=True)\n",
    "        for (count, folder), files in groupby(all_files, itemgetter(0, 1)):\n",
    "            sub_directory.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Save Each Model (different checkpoints)#####\n",
    "for modelpath in model_list: \n",
    "    # Load model\n",
    "    K.clear_session()\n",
    "    model = modellib.MaskRCNN(\n",
    "        mode=\"inference\", config=CellInferenceConfig(), model_dir=data_dir)\n",
    "    # Load weights from H5\n",
    "    model.load_weights(modelpath, by_name=True)\n",
    "    sess = K.get_session()\n",
    "\n",
    "    outputs = [output.name for output in model.keras_model.outputs]\n",
    "    outs = {str(o):sess.graph.get_tensor_by_name(o) for o in outputs}\n",
    "    output_names_all = [output.split(':')[0] for output in outputs]\n",
    "    \n",
    "    # Save model\n",
    "    tf.saved_model.simple_save(sess,\n",
    "                               model_dirpath+\"/savedmodel_%s/\" % modelpath.split('/')[-1][-7:-3],\n",
    "                               inputs={'input_image':model.keras_model.inputs[0], \n",
    "                                       'input_image_meta':model.keras_model.inputs[1],\n",
    "                                       'input_anchors':model.keras_model.inputs[2]},\n",
    "                               outputs=outs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "328px",
    "width": "719px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
