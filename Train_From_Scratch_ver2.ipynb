{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade pip\n",
    "!pip3 install --upgrade pip\n",
    "!pip install opencv-rolling-ball\n",
    "\n",
    "import sys\n",
    "import sagemaker\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import io\n",
    "import boto3\n",
    "import numpy as np\n",
    "from skimage import util \n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage import exposure\n",
    "from skimage.io import imread as pngread\n",
    "from skimage.io import imsave as pngsave\n",
    "import cv2\n",
    "from rolling_ball_filter import rolling_ball_filter\n",
    "import random\n",
    "import threading\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage import color\n",
    "from sagemaker import get_execution_role\n",
    "from IPython.core.debugger import set_trace\n",
    "from processfiles import *\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "training_image = get_image_uri(sess.boto_region_name, 'semantic-segmentation', repo_version=\"latest\")\n",
    "print (training_image)\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3meadata = s3_resource.Bucket(name='meadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run process functions (raw and filtered versions of fig8 and liorP)\n",
    "def procfilepar(key):\n",
    "    proccessliorpreprocfiles(key)\n",
    "    proccessliorfiles(key)\n",
    "    proccessfigure8files(key)\n",
    "    proccessfig8preprocfiles(key)\n",
    "    proccessusiigacifiles(key)\n",
    "    proccesshelafiles(key)\n",
    "    \n",
    "keys = [obj.key for obj in s3meadata.objects.all()]\n",
    "for key in keys:\n",
    "    t = threading.Thread(target = procfilepar, args=(key,)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop dataset images around labeled areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [obj.key for obj in s3_resource.Bucket(name=bucket).objects.all() if ('jpg' in obj.key and prefix in obj.key)]\n",
    "for key in keys:\n",
    "     t = threading.Thread(target = performcrop, args=(key,)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete all files without a matching image-annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeunmatched()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove samples with few segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "train_annotation_channel = prefix + '/train_annotation'\n",
    "validation_annotation_channel = prefix + '/validation_annotation'\n",
    "keys = [obj.key for obj in s3_resource.Bucket(name=bucket).objects.all() if ('png' in obj.key and prefix in obj.key)]\n",
    "segs = []\n",
    "empties = []\n",
    "for key in keys:\n",
    "    masksavepath = \"/tmp/\"+key.split('/')[-1]\n",
    "    s3.meta.client.download_file(bucket, key , masksavepath)\n",
    "    mask = cv2.imread(masksavepath)\n",
    "    segs.append([np.sum(mask==1)])\n",
    "    empties.append([np.sum(mask==0)])\n",
    "\n",
    "ratio = ((np.asarray(segs)/np.asarray(empties))*100).ravel()\n",
    "thresh = np.round(np.mean(ratio)-np.std(ratio))\n",
    "plt.hist(ratio)\n",
    "plt.show()\n",
    "df = pd.DataFrame({'key':keys, 'ratio':ratio,'empty':ratio<thresh})\n",
    "removesamples = df['key'].loc[np.where(df['empty'].values)].values\n",
    "for removeme in removesamples:\n",
    "    boto3.client('s3').delete_object(Bucket = bucket, Key = removeme)\n",
    "    boto3.client('s3').delete_object(Bucket = bucket, Key = removeme.replace('_annotation/','/').replace('png','jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "label_map = { \"scale\": 1 }\n",
    "with open('train_label_map.json', 'w') as lm_fname:\n",
    "    json.dump(label_map, lm_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print(s3_output_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sagemaker estimator object.\n",
    "ss_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count = 1, \n",
    "                                         train_instance_type = 'ml.p3.16xlarge',\n",
    "                                         train_volume_size = 300, # size in gb on s3 to reserve\n",
    "                                         train_max_run = 360000,\n",
    "                                         output_path = s3_output_location,\n",
    "                                         base_job_name = 'fresh-train-trial',\n",
    "                                         sagemaker_session = sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup hyperparameters \n",
    "import boto3\n",
    "s3traindata = boto3.resource('s3').Bucket(name=bucket)\n",
    "numtrain = len([obj.key for obj in s3traindata.objects.all() if ('train/' in obj.key and 'jpg' in obj.key)])\n",
    "ss_model.set_hyperparameters(backbone='resnet-101', # This is the encoder. Other option is resnet-50\n",
    "                             algorithm='deeplab', # This is the decoder. Other option is 'psp' and 'deeplab'                             \n",
    "                             use_pretrained_model='False', # Use the pre-trained model.\n",
    "                             crop_size=412, # Size of image random crop.                             \n",
    "                             num_classes=2, # Background + cell \n",
    "                             epochs=1000, # Number of epochs to run.\n",
    "                             learning_rate=0.003037052721870563, momentum = 0.6133596510181524, weight_decay = 0.0001560844683426084,                           \n",
    "                             optimizer='adagrad', # Other options include 'adam', 'rmsprop', 'nag', 'adagrad'.\n",
    "                             lr_scheduler='poly', # Other options include 'cosine' and 'step'.                           \n",
    "                             mini_batch_size=35, # Setup some mini batch size.\n",
    "                             validation_mini_batch_size=16, #try larger batch sizes maybe? \n",
    "                             early_stopping=True, # Turn on early stopping. If OFF, other early stopping parameters are ignored.\n",
    "                             early_stopping_patience=50, # Tolerate these many epochs if the mIoU doens't increase.\n",
    "                             early_stopping_min_epochs=25, # No matter what, run these many number of epochs.                             \n",
    "                             num_training_samples=numtrain) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup data inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full bucket names\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)\n",
    "s3_train_annotation = 's3://{}/{}'.format(bucket, train_annotation_channel)\n",
    "s3_validation_annotation = 's3://{}/{}'.format(bucket, validation_annotation_channel)\n",
    "\n",
    "distribution = 'FullyReplicated'\n",
    "# Create sagemaker s3_input objects\n",
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution=distribution, \n",
    "                                        content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution=distribution, \n",
    "                                        content_type='image/jpeg', s3_data_type='S3Prefix')\n",
    "train_annotation = sagemaker.session.s3_input(s3_train_annotation, distribution=distribution, \n",
    "                                        content_type='image/png', s3_data_type='S3Prefix')\n",
    "validation_annotation = sagemaker.session.s3_input(s3_validation_annotation, distribution=distribution, \n",
    "                                        content_type='image/png', s3_data_type='S3Prefix')\n",
    "\n",
    "data_channels = {'train': train_data, \n",
    "                 'validation': validation_data,\n",
    "                 'train_annotation': train_annotation, \n",
    "                 'validation_annotation':validation_annotation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model and deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "ss_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model to an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_predictor = ss_model.deploy(initial_instance_count=1, instance_type='ml.c4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an image for segmenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(64,64))\n",
    "# images/liorp_181106_2_raw.jpg\n",
    "filename = \"/home/ec2-user/SageMaker/itzik_images_cropped/_B37-543-2_07_ver2.tif\"\n",
    "# filename = \"/home/ec2-user/SageMaker/images/190221_LV_ver2.tif\"\n",
    "im = cv2.imread(filename)\n",
    "# selem = disk(60)\n",
    "# inimage = rank.equalize(inimage, selem=selem)  \n",
    "# im = clahe.apply(im)\n",
    "# im,_ = rolling_ball_filter(im, ball_radius = 20, spacing = 1, top=False)\n",
    "im =  cv2.resize(im, (1024,1024), interpolation = cv2.INTER_AREA)\n",
    "num = int(''.join(filter(str.isdigit, str(im.dtype)))) - 1\n",
    "im = img_as_ubyte(exposure.rescale_intensity(im, out_range=(0, 2**num - 1)))\n",
    "pngsave(filename.replace('tif','jpg'), im)\n",
    "\n",
    "with open(filename.replace('tif','jpg'), 'rb') as image:\n",
    "    img = image.read()    \n",
    "    img = bytearray(img)\n",
    "\n",
    "fig1 = plt.figure(figsize=(10, 10)) # create a figure with the default size \n",
    "ax1 = fig1.add_subplot(1,1,1) \n",
    "ax1.imshow(Image.open(io.BytesIO(img)), interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "ss_predictor.content_type = 'image/jpeg'\n",
    "ss_predictor.accept = 'image/png'\n",
    "return_img = ss_predictor.predict(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us display the segmentation mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "import seaborn as sns\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "num_classes = 2\n",
    "mask = np.array(Image.open(io.BytesIO(return_img)))\n",
    "distance = ndi.distance_transform_edt(mask)\n",
    "local_maxi = peak_local_max(distance, labels=mask, footprint=np.ones((3, 3)), indices=False)\n",
    "markers = ndi.label(local_maxi)[0]\n",
    "labels = watershed(-distance, markers, mask=mask)\n",
    "pngsave('/home/ec2-user/SageMaker/testresult_mask.tif', mask)\n",
    "\n",
    "fig1 = plt.figure(figsize=(20, 20)) # create a figure with the default size \n",
    "ax1 = fig1.add_subplot(2,2,1) \n",
    "result = label2rgb(label = labels, image = exposure.rescale_intensity(im.astype(np.float), out_range=(-1, 1)))\n",
    "ax1.imshow(result)\n",
    "ax2 = fig1.add_subplot(2,2,2) \n",
    "ax2.imshow(labels)\n",
    "plt.show()\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(ss_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inference on deployed model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessed submitted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure,color, img_as_int, img_as_ubyte\n",
    "from skimage.io import imread as pngread\n",
    "from skimage.io import imsave as pngsave\n",
    "from rolling_ball_filter import rolling_ball_filter\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters.rank import autolevel,equalize\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "\n",
    "def preproc(img):\n",
    "    selem = disk(60)\n",
    "    try:\n",
    "        img = autolevel(img, selem)\n",
    "        img = exposure.adjust_gamma(img, 2)\n",
    "        img = cv2.bilateralFilter(img,9,75,75)\n",
    "    except:\n",
    "        print(img.shape)\n",
    "        pass\n",
    "    return(img)\n",
    "\n",
    "def createmultipleinputs(inputpath):\n",
    "    # pad to square\n",
    "    im = pngread(inputpath)\n",
    "    if len(im.shape)==3:\n",
    "        print('Images should be grayscale but had dimensions {} - automatically converted'.format(im.shape))\n",
    "        im = np.sum(im,2)\n",
    "    im = np.uint8(img_as_int(exposure.rescale_intensity(im, out_range=(0, 2**15 - 1))))\n",
    "    imshape =im.shape\n",
    "    edgediff = np.max(imshape)-np.min(imshape)\n",
    "    orig = im\n",
    "    if imshape[0]>imshape[1]:\n",
    "        orig = cv2.copyMakeBorder(im, math.ceil(edgediff/2), math.ceil(edgediff/2), 0, 0, cv2.BORDER_CONSTANT,value=[0,0,0])\n",
    "    if imshape[0]>imshape[1]:\n",
    "        orig = cv2.copyMakeBorder(im, 0, 0, math.ceil(edgediff/2), math.ceil(edgediff/2), cv2.BORDER_CONSTANT,value=[0,0,0])\n",
    "    \n",
    "    # ==>resize to 1024\n",
    "    im1024 = cv2.resize(orig, (1024,1024), interpolation = cv2.INTER_AREA)\n",
    "    # ==>resize to 720\n",
    "    im720 = cv2.resize(orig, (720,720), interpolation = cv2.INTER_AREA)\n",
    "    # preprocess both\n",
    "    im1024preproc = preproc(im1024)\n",
    "    im720preproc = preproc(im720)\n",
    "    return([orig, im1024preproc,im720preproc, im1024, im720])\n",
    "\n",
    "def populate_inputs(localpaths,batchid = ''):\n",
    "    os.makedirs('/tmp/{}/'.format(batchid), exist_ok=True)\n",
    "    imlabels = ['orig', 'im1024pp','im720pp','im1024','im720']\n",
    "    for filepath in localpaths:\n",
    "        resimages =  createmultipleinputs(filepath)\n",
    "        for idx in range(0,len(resimages)):\n",
    "            savepath = '/tmp/'+batchid+'/'+batchid+'_'+filepath.split('.')[0].split('/')[-1]+'__'+imlabels[idx]+'.jpg'\n",
    "            pngsave(savepath,resimages[idx])\n",
    "    os.system(\"aws s3 sync '/tmp/{}/' 's3://sagemaker-eu-west-1-102554356212/submissions/{}/' \".format(batchid,batchid))\n",
    "inputpath = '/home/ec2-user/SageMaker/itzik_images_cropped/'        \n",
    "files = os.listdir(inputpath)\n",
    "files = [os.path.join(inputpath,f) for f in files if '.jpg' in f or '.png' in f or '.tif' in f]        \n",
    "populate_inputs(files, batchid='itzik') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run batch job from a saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::102554356212:role/service-role/AmazonSageMaker-ExecutionRole-20181129T100657\n"
     ]
    }
   ],
   "source": [
    "#Batch Job\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "from IPython.core.debugger import set_trace\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "# model_id = \"fresh-train-trial-2019-07-28-08-49-49-994\"\n",
    "# model_id = \"semantic-segmentatio-190726-1931-032-e7d26e04\"\n",
    "\n",
    "def runbatch(model_id, batchid=''):\n",
    "    env = {'SAGEMAKER_MODEL_SERVER_TIMEOUT' : '3600' }\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    s3results = s3_resource.Bucket(name='sagemaker-eu-west-1-102554356212')\n",
    "    removesamples = [obj.key for obj in s3results.objects.all() if (\"results_\"+model_id in obj.key and (\"out\" in obj.key or \"masks\" in obj.key))]\n",
    "    for removeme in removesamples:\n",
    "        boto3.client('s3').delete_object(Bucket = bucket, Key = removeme)\n",
    "\n",
    "    transform_job = sagemaker.transformer.Transformer(\n",
    "        model_name = model_id, \n",
    "        instance_count = 1,\n",
    "        instance_type = 'ml.p3.2xlarge',\n",
    "        strategy = 'SingleRecord',\n",
    "        assemble_with = 'None',\n",
    "        output_path = \"s3://sagemaker-eu-west-1-102554356212/results_{}/{}/\".format(model_id,batchid),\n",
    "        base_transform_job_name='inference-pipelines-batch',\n",
    "        sagemaker_session=sess,\n",
    "        accept = 'image/png',\n",
    "        env = env)\n",
    "    transform_job.transform(data = 's3://sagemaker-eu-west-1-102554356212/submissions/' , \n",
    "                            content_type = 'image/jpeg', \n",
    "                            split_type = None)\n",
    "\n",
    "runbatch(\"semantic-segmentatio-190726-1931-032-e7d26e04\")\n",
    "runbatch(\"fresh-train-trial-2019-07-28-08-49-49-994\")\n",
    "# transform_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read batch processed results and export mask back to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Download data from batch job\n",
    "import boto3\n",
    "import mxnet as mx\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "from skimage.io import imread as pngread\n",
    "from skimage.io import imsave as pngsave\n",
    "\n",
    "def batch2masks(model_id, batchid = ''):\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    s3results = s3_resource.Bucket(name='sagemaker-eu-west-1-102554356212')\n",
    "    keys = [obj.key for obj in s3results.objects.all()]\n",
    "    os.makedirs('/tmp/results/', exist_ok=True)\n",
    "    for s3_object in keys:\n",
    "        if not s3_object.endswith(\"/\") and \"results_\"+model_id+\"/\" in s3_object and \"out\" in s3_object:\n",
    "                s3.meta.client.download_file('sagemaker-eu-west-1-102554356212', s3_object, '/tmp/tempfile.out')\n",
    "                with open('/tmp/tempfile.out', 'rb') as image:\n",
    "                    img = image.read()    \n",
    "                    img = bytearray(img)\n",
    "                    mask = np.array(Image.open(io.BytesIO(img)))\n",
    "                    pngsave('/home/ec2-user/SageMaker/tmp/'+'.'.join(s3_object.split('/')[-1].split('.')[:-1]), mask)\n",
    "#     os.system(\"aws s3 sync '/tmp/results/{}/' 's3://sagemaker-eu-west-1-102554356212/results_{}/masks/' \".format(batchid,model_id))\n",
    "\n",
    "batch2masks(\"fresh-train-trial-2019-07-28-08-49-49-994\")\n",
    "batch2masks(\"semantic-segmentatio-190726-1931-032-e7d26e04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge multiple masks from different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processfiles import *\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.color import label2rgb\n",
    "import threading\n",
    "s3 = boto3.resource('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3results = s3_resource.Bucket(name='sagemaker-eu-west-1-102554356212')\n",
    "keys = [obj.key for obj in s3results.objects.all()]\n",
    "for s3_object in keys:\n",
    "    t = threading.Thread(target = merge_masks, args=(s3_object,[\"fresh-train-trial-2019-07-28-08-49-49-994\",\"semantic-segmentatio-190726-1931-032-e7d26e04\"],batchid,)).start()\n",
    "!aws s3 sync '/tmp/results/merge/merged/' 's3://sagemaker-eu-west-1-102554356212/results_merged/masks/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge multiple masks from different inputs (different pre-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from processfiles import *\n",
    "from scipy import ndimage as ndi\n",
    "import threading\n",
    "\n",
    "def merge_masks_diff_inputs(groupkeys, batchid = ''):\n",
    "    os.makedirs('/tmp/results/'+batchid+'/', exist_ok=True)\n",
    "    outpaths = []\n",
    "    for s3_object in groupkeys:\n",
    "        outpath = os.path.join('/tmp/results/'+s3_object.split('/')[-1])\n",
    "        s3.meta.client.download_file('sagemaker-eu-west-1-102554356212', s3_object, outpath)\n",
    "        pngsave(outpath,cv2.resize(pngread(outpath), (1024,1024), interpolation = cv2.INTER_AREA))\n",
    "        outpaths.append(outpath)\n",
    "    print(outpaths)\n",
    "    if outpaths:            \n",
    "        binarymask = merge_two_masks(outpaths)\n",
    "        num_classes = 2\n",
    "        distance = ndi.distance_transform_edt(binarymask)\n",
    "        local_maxi = peak_local_max(distance, labels=binarymask, footprint=np.ones((3, 3)), indices=False)\n",
    "        markers = ndi.label(local_maxi)[0]\n",
    "        mask = watershed(-distance, markers, mask=binarymask)\n",
    "        savepath = os.path.join('/tmp/results/'+batchid+'/inputmerged/',s3_object.split('/')[-1].split('__')[0].replace('merged_','inputmerged_')+'.jpg')\n",
    "        pngsave(savepath, np.uint8(mask>0))\n",
    "\n",
    "batchid = 'itzik'\n",
    "s3 = boto3.resource('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3results = s3_resource.Bucket(name='sagemaker-eu-west-1-102554356212')\n",
    "keys = [obj.key for obj in s3results.objects.all() if (not obj.key.endswith(\"/\")) and (\"merged\" in obj.key and batchid in obj.key)]\n",
    "df = pd.DataFrame({'keys':keys,'orig_name':[k.split('/')[-1].split('__')[1].split('.jpg')[0] for k in keys]})\n",
    "originals = np.unique(df['orig_name'].values)\n",
    "for org in originals:\n",
    "#      t = threading.Thread(target = merge_masks_diff_inputs, args=(df['keys'].loc[df['orig_name']==org].values,bid,)).start()\n",
    "    merge_masks_diff_inputs(groupkeys = df['keys'].loc[df['orig_name']==org].values,batchid = batchid)\n",
    "# !aws s3 sync '/tmp/results/merge/input_merged/' 's3://sagemaker-eu-west-1-102554356212/results_merged/input_merged_masks/'\n",
    "# os.system(\"aws s3 sync '/tmp/results/{}/' 's3://sagemaker-eu-west-1-102554356212/results_merged/masks_{}/' \".format(batchid,batchid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Input Pipeline (for inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "def randomString(stringLength=10):\n",
    "    \"\"\"Generate a random string of fixed length \"\"\"\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(stringLength))\n",
    "\n",
    "# def submitimages(input_dir_path,batchid = randomString(10)):\n",
    "\n",
    "input_dir_path = \"/home/ec2-user/SageMaker/itzik_images_cropped/\"\n",
    "for filename in os.listdir(input_dir_path): \n",
    "    os.rename(filename,filename.replace('_','-'))\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3results = s3_resource.Bucket(name='sagemaker-eu-west-1-102554356212')\n",
    "#create different inputs\n",
    "files = os.listdir(input_dir_path)\n",
    "files = [os.path.join(inputpath,f) for f in files if '.jpg' in f or '.png' in f or '.tif' in f]        \n",
    "populate_inputs(files, batchid = batchid) \n",
    "#model1 - infer mask for all inputs\n",
    "runbatch(\"semantic-segmentatio-190726-1931-032-e7d26e04\", batchid = batchid)\n",
    "#model2 - infer mask for all inputs\n",
    "runbatch(\"fresh-train-trial-2019-07-28-08-49-49-994\", batchid = batchid)\n",
    "#merge masks from different models\n",
    "keys = [obj.key for obj in s3results.objects.all() if batchid in obj.key]\n",
    "for key in keys:\n",
    "    t = threading.Thread(target = merge_masks, args=(key,[\"fresh-train-trial-2019-07-28-08-49-49-994\",\"semantic-segmentatio-190726-1931-032-e7d26e04\"],batchid)).start()\n",
    "os.system(\"aws s3 sync '/tmp/results/{}/merge/merged/ 's3://sagemaker-eu-west-1-102554356212/results_merged/{}/masks/'\".format(batchid,batchid))\n",
    "#merge masks from different inputs\n",
    "keys = [obj.key for obj in s3results.objects.all() if ('results_merged' in obj.key and 'masks' in obj.key and batchid in obj.key)]\n",
    "df = pd.DataFrame({'keys':keys,'orig_name':[k.split('/')[-1].split('__')[1].split('.jpg')[0] for k in keys]})\n",
    "originals = np.unique(df['orig_name'].values)\n",
    "for org in originals: \n",
    "          merge_masks_diff_inputs(groupkeys = df['keys'].loc[df['orig_name']==org].values,batchid = batchid)\n",
    "os.system(\"aws s3 sync '/tmp/results/{}/merge/merged/ 's3://sagemaker-eu-west-1-102554356212/results_merged/{}/masks/'\".format(batchid,batchid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
