{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:52:51.949187Z",
     "start_time": "2018-12-15T13:52:29.593597Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# General System stuff\n",
    "import sys\n",
    "import gc\n",
    "import glob\n",
    "import os\n",
    "from os.path import getsize\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "IOU_THRESHOLD = 0.6\n",
    "OVERLAP_THRESHOLD = 0.8\n",
    "MIN_DETECTIONS = 1\n",
    "\n",
    "#--------------------------------------#\n",
    "\n",
    "# Processing stuff\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import operator\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "#--------------------------------------#\n",
    "\n",
    "# Deep learning and GPU stuff\n",
    "from keras import backend as K\n",
    "from numba import cuda\n",
    "import tensorflow as tf \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "import googleapiclient.discovery as discovery\n",
    "\n",
    "sys.path.insert(0, '/home/mestalbet/Segment2P/mrcnn')\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import utils\n",
    "from train import cellConfig\n",
    "\n",
    "#--------------------------------------#\n",
    "\n",
    "# Image Stuff\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tifffile import imsave,imread\n",
    "from skimage import exposure\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import io as skio\n",
    "from skimage import util\n",
    "\n",
    "#--------------------------------------#\n",
    "\n",
    "# File Handling\n",
    "import datetime\n",
    "import time\n",
    "from glob import glob\n",
    "import csv\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "\n",
    "#--------------------------------------#\n",
    "\n",
    "# GUI\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "#--------------------------------------#\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import colorsys\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import plotly.offline as offline\n",
    "plotly.offline.init_notebook_mode(connected=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outpath = \"/home/mestalbet/PythonScripts/Results_LiorImages/\"\n",
    "# data_dir = \"gs://segproj/PythonScripts/Results_LiorImages/inference/pngs/\"\n",
    "data_dir = \"/home/mestalbet/bucket/PythonScripts/Results_LiorImages/inference/pngs/\"\n",
    "# data_dir = os.path.join(outpath,\"inference/\")\n",
    "model_path_1 = \"/home/mestalbet/Segment2P/TrainWeights/mask_rcnn_cell_0100.h5\"\n",
    "model_path_2 = \"/home/mestalbet/Segment2P/TrainWeights/mask_rcnn_cell_0198.h5\"\n",
    "model_path_3 = \"/home/mestalbet/Segment2P/TrainWeights/mask_rcnn_cell_0199.h5\"\n",
    "model_path_4 = \"/home/mestalbet/Segment2P/TrainWeights/mask_rcnn_cell_0200.h5\"\n",
    "model_list = [model_path_1, model_path_2, model_path_3, model_path_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Configuration class\n",
    "chunksize = 1\n",
    "class CellInferenceConfig(cellConfig):\n",
    "        # Set batch size to 1 to run one image at a time\n",
    "        GPU_COUNT = 1\n",
    "        IMAGES_PER_GPU = chunksize\n",
    "        # Don't resize imager for inferencing\n",
    "        IMAGE_RESIZE_MODE = \"pad64\"\n",
    "        # Non-max suppression threshold to filter RPN proposals.\n",
    "        # You can increase this during training to generate more propsals.\n",
    "        RPN_NMS_THRESHOLD = 0.7\n",
    "        # define the folder path to data for prediction\n",
    "        global data_dir\n",
    "        all_files = []\n",
    "        sub_directory = []\n",
    "        for root, dirs, files in os.walk(data_dir):\n",
    "            for file in files:\n",
    "                relativePath = os.path.relpath(root, data_dir)\n",
    "                if relativePath == \".\":\n",
    "                    relativePath = \"\"\n",
    "                all_files.append(\n",
    "                    (relativePath.count(os.path.sep), relativePath, file))\n",
    "        all_files.sort(reverse=True)\n",
    "        for (count, folder), files in groupby(all_files, itemgetter(0, 1)):\n",
    "            sub_directory.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Setup Path Iterator ######\n",
    "\n",
    "#Delete old models\n",
    "# os.system(\"rm /home/mestalbet/bucket/PythonScripts/savedmodel/ver* -r\") \n",
    "\n",
    "dirs = os.listdir(\"/home/mestalbet/bucket/PythonScripts/savedmodel/\") \n",
    "vernum = [int(d[-1]) for d in dirs]\n",
    "if not vernum:\n",
    "    vernum = 0\n",
    "else:\n",
    "    vernum = np.max(vernum)\n",
    "model_dirpath = \"/home/mestalbet/bucket/PythonScripts/savedmodel/ver%d\" % (vernum+1)\n",
    "if not os.path.exists(model_dirpath):\n",
    "    os.makedirs(model_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Save Each Model (different checkpoints)#####\n",
    "for modelpath in model_list: \n",
    "    # Load model\n",
    "    K.clear_session()\n",
    "    model = modellib.MaskRCNN(\n",
    "        mode=\"inference\", config=CellInferenceConfig(), model_dir=data_dir)\n",
    "    # Load weights from H5\n",
    "    model.load_weights(modelpath, by_name=True)\n",
    "    sess = K.get_session()\n",
    "\n",
    "    outputs = [output.name for output in model.keras_model.outputs]\n",
    "    outs = {str(o):sess.graph.get_tensor_by_name(o) for o in outputs}\n",
    "    output_names_all = [output.split(':')[0] for output in outputs]\n",
    "    \n",
    "    # Save model\n",
    "    tf.saved_model.simple_save(sess,\n",
    "                               model_dirpath+\"/savedmodel_%s/\" % modelpath.split('/')[-1][-7:-3],\n",
    "                               inputs={'input_image':model.keras_model.inputs[0], \n",
    "                                       'input_image_meta':model.keras_model.inputs[1],\n",
    "                                       'input_anchors':model.keras_model.inputs[2]},\n",
    "                               outputs=outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelpath = model_list[0]\n",
    "# K.clear_session()\n",
    "# model = modellib.MaskRCNN(mode=\"inference\", config=CellInferenceConfig(), model_dir=data_dir)\n",
    "# # Load weights from H5\n",
    "# model.load_weights(modelpath, by_name=True)\n",
    "# model = model.keras_model\n",
    "# sess = K.get_session()\n",
    "\n",
    "# outputs = [output.name for output in model.outputs]\n",
    "# outs = {str(o):sess.graph.get_tensor_by_name(o) for o in outputs}\n",
    "\n",
    "# outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "imgpath = \"/home/mestalbet/PythonScripts/Results_LiorImages/inference/\"\n",
    "predict_instance_json = \"/home/mestalbet/bucket/PythonScripts/submit_data/inputs.json\"\n",
    "os.system(\"rm %s\" % (predict_instance_json))\n",
    "config=CellInferenceConfig()\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=data_dir)\n",
    "model.load_weights(model_path_1, by_name=True)\n",
    "\n",
    "class ImageDataset(utils.Dataset):\n",
    "    def load_images(self, dataset_dir):\n",
    "        \"\"\"\n",
    "        Loads dataset images.\n",
    "        :param dataset_dir: string, path to dataset directory.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.add_class(\"cell\", 1, \"cell\")\n",
    "\n",
    "        image_ids = [fn for fn in os.listdir(dataset_dir)\n",
    "                     if any(fn.endswith(ext) for ext in ['tif', \"png\"])]\n",
    "\n",
    "        for image_id in image_ids:\n",
    "            self.add_image(\n",
    "                'cell',\n",
    "                image_id=os.path.splitext(image_id)[0],\n",
    "                path=os.path.join(dataset_dir, image_id)\n",
    "            )\n",
    "dataset = ImageDataset()\n",
    "dataset.load_images(imgpath)\n",
    "dataset.prepare()\n",
    "with open(predict_instance_json, \"w+\") as fp:\n",
    "    for image_id in dataset.image_ids:\n",
    "        image = dataset.load_image(image_id)\n",
    "        active_class_ids = np.zeros([dataset.num_classes], dtype=np.int32)\n",
    "        source_class_ids = dataset.source_class_ids[dataset.image_info[image_id][\"source\"]]\n",
    "        active_class_ids[source_class_ids] = 1\n",
    "        img, window, scale, padding, crop = utils.resize_image(\n",
    "                image,\n",
    "                min_dim=config.IMAGE_MIN_DIM,\n",
    "                min_scale=config.IMAGE_MIN_SCALE,\n",
    "                max_dim=config.IMAGE_MAX_DIM,\n",
    "                mode=config.IMAGE_RESIZE_MODE)\n",
    "        meta = np.array(\n",
    "            [image_id] +                  # size=1\n",
    "            list(image.shape) +           # size=3\n",
    "            list(img.shape) +             # size=3\n",
    "            list(window) +                # size=4 (y1, x1, y2, x2) in image cooredinates\n",
    "            [scale] +                     # size=1\n",
    "            list(active_class_ids)        # size=num_classes\n",
    "            )\n",
    "        anchors = model.get_anchors(image.shape)\n",
    "        json_data = {'input_image':image.tolist(),\n",
    "                     'input_image_meta':meta.tolist(),\n",
    "                     'input_anchors':anchors.tolist()} #,'key':int(image_id)\n",
    "        jline = json.dumps(json_data) + \"\\n\"\n",
    "        fp.write(jline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit job to cloud\n",
    "# ------------------------------------------#\n",
    "# Define batch job submission vfunction\n",
    "def make_batch_job_body(project_name, input_paths, output_path,\n",
    "                        model_name, region, data_format='JSON',\n",
    "                        version_name=None, max_worker_count=None,\n",
    "                        runtime_version=None):\n",
    "\n",
    "    project_id = 'projects/{}'.format(project_name)\n",
    "    model_id = '{}/models/{}'.format(project_id, model_name)\n",
    "    if version_name:\n",
    "        version_id = '{}/versions/{}'.format(model_id, version_name)\n",
    "\n",
    "    # Make a jobName of the format \"model_name_batch_predict_YYYYMMDD_HHMMSS\"\n",
    "    timestamp = time.strftime('%Y%m%d_%H%M%S', time.gmtime())\n",
    "\n",
    "    # Make sure the project name is formatted correctly to work as the basis\n",
    "    # of a valid job name.\n",
    "    clean_project_name = re.sub(r'\\W+', '_', project_name)\n",
    "\n",
    "    job_id = '{}_{}_{}'.format(clean_project_name, model_name,\n",
    "                           timestamp)\n",
    "\n",
    "    # Start building the request dictionary with required information.\n",
    "    body = {'jobId': job_id,\n",
    "            'predictionInput': {\n",
    "                'dataFormat': data_format,\n",
    "                'inputPaths': input_paths,\n",
    "                'outputPath': output_path,\n",
    "                'region': region}}\n",
    "\n",
    "    # Use the version if present, the model (its default version) if not.\n",
    "    if version_name:\n",
    "        body['predictionInput']['versionName'] = version_id\n",
    "    else:\n",
    "        body['predictionInput']['modelName'] = model_id\n",
    "\n",
    "    # Only include a maximum number of workers or a runtime version if specified.\n",
    "    # Otherwise let the service use its defaults.\n",
    "    if max_worker_count:\n",
    "        body['predictionInput']['maxWorkerCount'] = max_worker_count\n",
    "\n",
    "    if runtime_version:\n",
    "        body['predictionInput']['runtimeVersion'] = runtime_version\n",
    "\n",
    "    return body\n",
    "\n",
    "# Project definitions\n",
    "project_name = \"divine-builder-142611\"\n",
    "credentials_path = \"/home/mestalbet/bucket/PythonScripts/Segmentation Project-a5a157bd9401.json\"\n",
    "project_id = 'projects/{}'.format(project_name)\n",
    "input_paths = \"gs://segproj/PythonScripts/submit_data/\"\n",
    "output_path = \"gs://segproj/PythonScripts/cloud_output/\"\n",
    "model_name = \"segmentation\"\n",
    "region = \"us-central1\"\n",
    "\n",
    "# Submit job\n",
    "version_names = ['Model0100_Ver1_0','Model0198_Ver1_0','Model0199_Ver1_0','Model0200_Ver1_0']\n",
    "for vn in version_names:\n",
    "    op = os.path.join(output_path,vn)\n",
    "    if not os.path.exists(op):\n",
    "        os.makedirs(op)\n",
    "\n",
    "    dirs = os.listdir(op) \n",
    "    vernum = [int(d[-1]) for d in dirs]\n",
    "    if not vernum:\n",
    "        vernum = 0\n",
    "    else:\n",
    "        vernum = np.max(vernum)\n",
    "    op = os.path.join(op, \"run_%d\" % (vernum+1))\n",
    "    if not os.path.exists(op):\n",
    "        os.makedirs(op)\n",
    "        \n",
    "    batch_predict_body = make_batch_job_body(project_name, input_paths, op,\n",
    "                                             model_name, region, data_format='JSON',\n",
    "                                             version_name=vn, max_worker_count=None,\n",
    "                                             runtime_version=None)\n",
    "    ml = discovery.build('ml', 'v1')\n",
    "    request = ml.projects().jobs().create(parent=project_id,body=batch_predict_body)\n",
    "    response = request.execute()\n",
    "\n",
    "# developerKey=\"AIzaSyCmugrkm9rIUpn8AnAKxX8KaKZJU5Qjz6Q\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = model_list[0]\n",
    "K.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=CellInferenceConfig(), model_dir=data_dir)\n",
    "\n",
    "respath = \"/home/mestalbet/bucket/PythonScripts/cloud_output/\"\n",
    "resfiles = glob(respath+'prediction.results*')\n",
    "resfiles = [r for r in resfiles if getsize(r)>0]\n",
    "ishape = (1024, 1024, 3)\n",
    "mshape = (2048, 2048, 3)\n",
    "window = np.array([   0,    0, 2048, 2048])\n",
    "final_masks=[]\n",
    "for resfile in resfiles:\n",
    "    json_data=open(resfile).read()\n",
    "    data = json.loads(json_data)\n",
    "    _, _, _, fm = model.unmold_detections(\n",
    "                                np.asarray(data['mrcnn_detection/Reshape_1:0']), \n",
    "                                np.asarray(data['mrcnn_mask/Reshape_1:0']),\n",
    "                                ishape, mshape, window)\n",
    "    if (fm.shape[0]!=1024 or fm.shape[2]<1):\n",
    "        print(\"Image Output Size Error\")\n",
    "    else: \n",
    "        final_masks.append(np.argmax(fm,2))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mestalbet/anaconda3/envs/segproj/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
     ]
    }
   ],
   "source": [
    "respath = \"/home/mestalbet/bucket/PythonScripts/cloud_output/\"\n",
    "modelpath = model_list[0]\n",
    "K.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=CellInferenceConfig(), model_dir=data_dir)\n",
    "\n",
    "model_cp=[]\n",
    "model_ver=[]\n",
    "image_num=[] \n",
    "run_num=[]\n",
    "mask=[]\n",
    "ishape = (1024, 1024, 3)\n",
    "mshape = (2048, 2048, 3)\n",
    "window = np.array([   0,    0, 2048, 2048])\n",
    "for (dirpath, dirnames, filenames) in os.walk(respath):\n",
    "    for file in filenames:\n",
    "        resfile = os.path.join(dirpath, file)\n",
    "        if ('prediction.results' in resfile and getsize(resfile)>0):\n",
    "            json_data=open(resfile).read()\n",
    "            data = json.loads(json_data)\n",
    "            _, _, _, fm = model.unmold_detections(\n",
    "                                        np.asarray(data['mrcnn_detection/Reshape_1:0']), \n",
    "                                        np.asarray(data['mrcnn_mask/Reshape_1:0']),\n",
    "                                        ishape, mshape, window)\n",
    "            if (fm.shape[0]!=1024 or fm.shape[2]<1):\n",
    "                fm = np.zeros((1024,1024,2))\n",
    "            else:\n",
    "                model_cp.append(dirpath.split('/')[-2].split('_')[0])\n",
    "                model_ver.append(dirpath.split('/')[-2].split('_')[1])\n",
    "                image_num.append(int(file.split('-')[1]))\n",
    "                run_num.append(int(dirpath.split('/')[-1].split('_')[-1]))\n",
    "                mask.append(np.argmax(fm,2))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_cp</th>\n",
       "      <th>model_ver</th>\n",
       "      <th>image_num</th>\n",
       "      <th>run_num</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model0100</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model0100</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model0198</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model0198</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model0199</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Model0200</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Model0200</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Model0100</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Model0198</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Model0198</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_cp model_ver  image_num  run_num  \\\n",
       "0  Model0100      Ver1          0        1   \n",
       "1  Model0100      Ver1          0        2   \n",
       "2  Model0198      Ver1          0        1   \n",
       "3  Model0198      Ver1          0        2   \n",
       "4  Model0199      Ver1          0        1   \n",
       "5  Model0200      Ver1          0        1   \n",
       "6  Model0200      Ver1          0        2   \n",
       "7  Model0100      Ver1          1        2   \n",
       "8  Model0198      Ver1          1        1   \n",
       "9  Model0198      Ver1          1        2   \n",
       "\n",
       "                                                mask  \n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "5  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "6  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "7  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "8  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "9  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'model_cp':model_cp,\n",
    "                   'model_ver':model_ver,\n",
    "                   'image_num':image_num, \n",
    "                   'run_num':run_num,\n",
    "                   'mask':mask})\n",
    "df.sort_values(['image_num','model_cp','run_num'],inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'image_num':[], 'mask_avg':[]}\n",
    "for imnum in np.unique(df['image_num'].values):\n",
    "    masks = df[df['image_num']==imnum]['mask'].values.tolist()\n",
    "    results['image_num'].append(imnum)\n",
    "    results['mask_avg'].append(merge_multiple_detections(masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f44ac43d940>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAG49JREFUeJzt3XuwVeWZ5/HvIzfFiIhihgAJqJDgGK+Ei3al0pLWhEk1GS8TMknH2M5QNUkc05mkG5zKZCaZanXa6iTdY9vNxDbYcYJptEfLYYaOl1RXgiBgDGKIgErDERKgFXQ0RsBn/thrHxbn7Mu67LX2uvw+VbvO3u96915vVjg/n/dda69j7o6ISFwn9HsAIlJOCg8RSUThISKJKDxEJBGFh4gkovAQkURyDw8z+4iZPWdmO8xsad77F5HesDyv8zCzEcA24HeAAWAD8El3/3lugxCRnsi78pgD7HD3F9z9LWAlsCjnMYhID4zMeX+Tgd2h1wPA3HAHM1sCLAEYwYhLxjIuv9GldNKs3n7er7f29vOK4vTz3or9nn/aMjqDkXR39vn/r+225ze/I8eRZOc1Xjng7hPjvi/v8LAWbcfNm9x9ObAcYJxN8Lm2II9x9cR59/a2kNtyyds9/byi+MwDu7t3auGe907t8Ug6u39gHXBy135XT5mX/WAy9Iiv+sck78t72jIAhP8FTAH25DwGKanPPJcsdCQbeYfHBmCGmU03s9HAYuChnMdQClWtOqqoUaHUT67TFnc/YmZfANYAI4C/dvdn8xyDiPRG3mseuPtqYHXe+y0TVR2t5b3mIZ3pCtMe2nLJ24OPNJ8hw+UdHIdWn8OHN386132WTe6VR10oBHqnXxXH+BN/HanfNduuxh4Dv/yljEdULKo8JHdRw+Ce907tS3AcWn3O4PNrtl3dsW+37VWmykP6okzrF+GAWDXz/raBYY9NrlX1ocpDJCRcdbRS50pjKIWHiCSi8BCRRBQeIpKIwkOkjYNvnhSrf50WS0HhISIJKTxEOjj45kmRKpC6VR2g6zxEIgkHyKkLd/RxJMWhykMkRMEQncJDRBJReIgMoeojGoWHSAvtAkTBcowWTEXaUFB0pspDRBJR5SHSB699ItqfazjlvuLeXFmVh0jOogZH3L55U3iI5KjIYRCXwkOk4IoaOAoPkZwUNQSSUngUyMCyS/s9BMlI1YIDdLalb9oFRbh9yi1r8xqOZOTNj83p9xAyo8qjD6JWGKpEyq3KwQGqPHIXNxAGll2qCqQg9j34vuNen7noF237Vj04QJVHKagC6a99D75vWHB0am8VHKNeT/4XBIt6oZjCQ6SDVuHQqk+UfmkCpIgUHiWh6kOKRuEh0kaUamJo/25rHVWqPrRgmsLIs6Z17XPkhZ2Zj0PKpRkgh08u93+7yz36PooSHHH6STW8+m9fjdy37FWIKo8E4gbCyLOmDVYgU25Zm3j94o2r5nbcPvaB9Yk+V3pn3P8YF6t/OEBaVSJFPdMCKSoPM5tqZo+b2VYze9bMbgraJ5jZD81se/DztKDdzOzPzGyHmW02s4t79T8iT0krifD7srpu442r5nYNGCmuUa+/zajX3+aU+9YNPooszbTlCPAf3H0WMA/4vJmdCywFHnX3GcCjwWuAjwIzgscS4M4U++6LtFOQNO+f8NzRVPuWfJz48JP9HkJuEoeHu+9196eC568BW4HJwCJgRdBtBfDx4Pki4B5vWAeMN7NJiUdeclleNarqozc6XUEqPVowNbNpwEXAeuCd7r4XGgEDnBl0mwzsDr1tIGgb+llLzGyjmW08zG96MbzCmnLL2kghoqqjHJphk6b6KFPlknrB1MzeAdwPfNHdXzWztl1btPmwBvflwHKAcTZh2PayCy+eNnUKkKRVxBtXzdUCag80A6HbNR9Dq5RwCET5nkuZQqMpVXiY2SgawXGvuz8QNP/KzCa5+95gWrIvaB8ApobePgXYk2b/edIp13pLM4UZGgzhMCljaDQlDg9rlBh3AVvd/U9Dmx4CrgNuDX4+GGr/gpmtBOYCh5rTG2lNaxfVFDUwTv6HiYPPX//g/qyGk1iayuMy4PeAZ8zs6aDtZhqh8QMzuwHYBVwbbFsNLAR2AG8A16fYt0hlhUNjaFuRQiRxeLj7j2m9jgGwoEV/Bz6fdH/9duSFnT2ZuuhydemkVXAM3V6UAKn9FaZ+2YVtt9lPnm67TVqzMWO69vHfVPssWlLdgqNoavvdFr/swo7BEbWPHBMlOOL0q5M4wVGUkKlleCQNhDJNOXSaVrJWq/BIWkn0qvqIGz5lCoC41YSqj/KrVXik0QyQpNVH0vfFDZCxD6zPPXSSBoECpNwUHgkceWFn5DCI07edqGFQpkpFyq824dGLqcfQz+gUCr0IjbBOFUU/qg3praKcfo2j9qdq08p7EbVoIaGpR33VpvIQKbqo1UdRqhRVHhX14srzI/edvnhzhiORqlLlUUFxgiNJf8nO6x/c37GyKErVAao8KkdBUA1FCol2alN51OF7KmmCQ6EjcdUmPKT3dKal3moVHmmrjzpULyJR1W7Nw37ydOwLxvIKjUOfntey/dTvRfv7HdMXb9b0Q3JTu/CA4lUQ7UIjvD1qgGThw1tea7Ol0f7oJWfkN5iI/vjFzrf6u3l695sSS2e1DI+i6BYaQ/tmGSDn3LiXVn/goX1wFFe34AAYMWtG1z5Ht27vxXAqq1ZrHkUSJzjivGf64s2xL/o658bGfahHTDz+JjNRg2PBpgOx9pelKMEB8I3V93btM2LWjEghU1cKjz5IEhxxNUNEV4+2FyVAIFqVUkeattRAM0CGVhatjJg4kaP798eerizYdKCQax+SHVUeNRElOMou6pRFekOVR86ynLL0MyCSVB29vov6zdPnxAqQry78VE/3XzeqPCqibJWF/vxC+Sk8pKVHzjsls88uQnCo6khP4VEi/bxQrJNHzjslciBkHRw3T5/T9QIwBUdvaM1D2nrkvFNinXVpBkOrL8zlXW3cPH2OTrFmTOFREp2qjizXO9oFSKdpTRGmJZI9hUcJdJuuHN2/P/MAKaOjW7f3pPrQZeqtac0jZ3HWLU793rrCrnOUhX7xs6PKow8UCPlKU4EofNpTeFTMG/ee3HH72E+9ntNIiqUZAnFCRMHRmaYtFXF0//6uwSHRA0HB0V3qysPMRgAbgZfc/WNmNh1YCUwAngJ+z93fMrMxwD3AJcA/AZ9w951p9y/wm7+fFrnvG/eeXNvqo0nB0Bu9qDxuAraGXt8GfNPdZwCvADcE7TcAr7j7OcA3g37SB6pQpBdShYeZTQH+BfCd4LUBlwOrgi4rgI8HzxcFrwm2Lwj6Swpxqg6RXkpbeXwL+EPg7eD16cBBdz8SvB4AJgfPJwO7AYLth4L+xzGzJWa20cw2HkYXG4kUVeLwMLOPAfvcfVO4uUVXj7DtWIP7cnef7e6zR6G/C5K3o/uL/5fKpBjSLJheBvyumS0ETgTG0ahExpvZyKC6mALsCfoPAFOBATMbCZwKvJxi/7WXdMoy5oqdLW92LBJH4srD3Ze5+xR3nwYsBh5z908BjwPXBN2uAx4Mnj8UvCbY/pi7D6s8RKQcsrjO44+AL5nZDhprGncF7XcBpwftXwKWZrDvWhlzxc5c3iPSSk+uMHX3HwE/Cp6/AAy7oYK7vwlc24v9SXwKDek1XWFact1CYcwVOxUckgl9t6UCFA7Vtus/Xdqy/d1fX5vzSI6n8BApoHaB0apPv0JE4SFSIFFCoyi05iEiiSg8RAqiTFUH1Hza8taVswefj16zsY8jkborW3BADcMjHBit2hUikrcyBgfUbNrSLjji9hGRGoWHQkGkt2oxbYkbHG9dOVvTlwxtW/6Blu0zl2zIeSTl188LxSpfeajiKI5tyz/QNjia26U8Kh8eSSl0eqdbaAztK9H0+/L0SoeHAqD/FAbdxQ2Bd399bd+DAyoeHiJlESUMihIaTbVYMJX+yLLq+PN//Mmwthvfc1lm+8tDkYIhCoWHlEqr0AhvK3uARLXnK60vLHvXn+QXQAqPjI2cMrl7J+DIwEsZj6T8OgVHuE9VA6RdYAztk1eAVHrNo9/XakQNjrh9pX6iBEeSvmlUOjzSSBs8ScJAAdIbUSqUstjzlUtzC4O4NG3JQFlC4MCS+YPPz1j+RB9HckwVrjLd9/lov+xn3tF5elHU0GiqfOUxes3G2FVEP6c7eQTPgSXzjwuOdm0SX9Tg6Na36MEBNao8Rq/ZWJqLxrZ/e17L9hk3rUv1uVHC4cCS+X2rQrpVHTe+57JCT0niBEcVVL7yiKsfax1NW78yla1fmdp2e7tQiaIfVcXMJRsqMQ2JImlwlDlwalN5QPfqo5/TlU6hEbb92/NSVyB562WAFLH66HUApJ2y5HWq1or852LH2QSfawv6PYxYklQeUYMjLE6AJKk6irKA2k0RrjRNGx6tFk6TBkiS4HjEV21y99hz+lpVHlI9Vb0grAy05iEiiSg8Kk6nX8spyfQjz++1gMJDWijLekdRdLvYK6k4YZB3cEAN1jzW7Hl68PmV77qwjyMRiS8cCkX4Jm1YpcMjHBxDXytIWsuq6vjlF6OdPfhn3yrXPS2azrxjbaKzLnGqln6FRDu1nbYMDZYqKsp6R9TgiNu3aM68Y21mU5giqmx49CscdF+O4yUJgzIHCNQnRFJNW8xsPPAd4DzAgd8HngPuA6YBO4F/5e6vmJkB3wYWAm8An3X3p9Lsvypm/cnuWBeKRb1A7IzlT8SqPno9ZSl7CACMGDeu7bajr77a8b1VD5C0lce3gf/r7u8DLgC2AkuBR919BvBo8Brgo8CM4LEEuDPlvivjyMBLkQMhq0vTi3aGpd/BM2LcuI7BEbVPlSUODzMbB3wQuAvA3d9y94PAImBF0G0F8PHg+SLgHm9YB4w3s0mJR15gUacuRwZeOq5v2b6zUkVJAqGuAZJm2nIWsB+428wuADYBNwHvdPe9AO6+18zODPpPBnaH3j8QtO0Nf6iZLaFRmXAiY1MMr7+Srn0MDZDmN2nrUnH0U5oQaL6321SmStJMW0YCFwN3uvtFwOscm6K0Yi3ahn0rz92Xu/tsd589ijGJB9ftVGxZTtXOuGldquDoFA4KjmN6VT3UqQpJU3kMAAPuvj54vYpGePzKzCYFVcckYF+of3hVcAqwJ8X+u7ryXRe2POtSluDoFYVEvkaMG1eLCiRxeLj7L81st5m9192fAxYAPw8e1wG3Bj8fDN7yEPAFM1sJzAUONac3WapbUFRFWS8Wa6pDgKS9wvRG4F4zGw28AFxPYyr0AzO7AdgFXBv0XU3jNO0OGqdqr0+5bxHpI90MSDKV5JRr3lVHlusUZag+dDMgKb2yT1XqRuEhmVIgVFdlv9siElUZphZFpPAQkUQUHiKSiMJDJCNVnw4pPESo/i96FnS2JeT527v/Ocezv6xvvkp3dQgjVR4xRQkYKade/cLXIThA4TFIoSCQ/he/LsEBCo9EFDTVliQAjr76aq2CA7TmASgMZLhmEHT73kvdAiNM4SHSQZ3DoRtNW0QkkUJXHtPf/xrfXf3jwdefffdv9XE0x+h0rUjJKo/v7vox39314+4dRSRzpQoPESmOUoaHqg+R/itlePRanDUMrXeINCg8AnUOhYH7//ngQySqQp9tydvZX15XmwvG2gVFs33K1c/mORwpIVUeQ1SpAvmXP98/+GiKWmGoCpFuFB4tVCFAwoHRfD20TSQNhUcbrQKkDKGikJC8aM2jgzKEhUi/qPKoEFUckieFR83cOOtH/R6CVITCQ6Ridn5jPju/MT/z/RR6zePFZ04pzDdpi05TlvpqFxRD26d99Yme7leVR838+dYPReqni8TKIU6F0etqROEhUlJ5TE06UXjIMKo6ii9pcPQycAq95lF1E9eOH3y+/9KDqT7r786dGGndQ8EgvZKq8jCzPzCzZ81si5l938xONLPpZrbezLab2X1mNjroOyZ4vSPYPq0X/wPKaOLa8ccFR7Mta3937sTM9yHZS1M99HLRNHF4mNlk4N8Ds939PGAEsBi4Dfimu88AXgFuCN5yA/CKu58DfDPoVyutQmPodpGySDttGQmcZGaHgbHAXuBy4F8H21cA/xm4E1gUPAdYBfx3MzN395RjKLy8QqHV1EXVhmQlcXi4+0tmdjuwC/g18PfAJuCgux8Jug0Ak4Pnk4HdwXuPmNkh4HTgQPhzzWwJsATgRMYmHV5p2QfeP/jcNzwT+/0KC8lL4vAws9NoVBPTgYPA3wIfbdG1WVlYh23HGtyXA8sBxtmESFXJtrsvadk+8/pNUd5eWM0gSRIiUl3TvvpEonWPXl8klmba8mHgRXffD2BmDwCXAuPNbGRQfUwB9gT9B4CpwICZjQROBV5OsX+gfXCEt/UiRHZ876Jhbed8+qepPzcK+8D7FSBSOGnCYxcwz8zG0pi2LAA2Ao8D1wArgeuAB4P+DwWvnwi2P5Z2vaNTcKTVKixEiiJp9dFLadY81pvZKuAp4AjwUxrTjf8NrDSz/xq03RW85S7gb8xsB42KY3HSfccNjW13XxKp+ihyYKj6kKHiBEivpyyQ8myLu38N+NqQ5heAOS36vglcm2Z/WSpycEi9THvypJbtO+f8enjfUCi0C5IsggNKeIVpFlOVpMGx43sXRVr32H/pQV3DIQC8eOt8pi9t/cvcLjTC21sFyOD2jEKinVKFR5ZrHFmLEiAHbpqa02gkLy/eOrwaCLc1g6RbcDR1C5A8lSo8iibu2RZVIPXRKjTa9fvty5/OeDTZKM23astcdYSpuqi+qMEBlDY4oEThkUbRLhY7cNPUYSGiUKmGOMFRdqWZtsy8flNlqo8mBUa11Ck4oGSVR5IKIquqI6+rS0WKqlThAY0w6HUgKAhE4ivNtGWocIC0ms7EDZhzPv3TSNd7pA0a3/DMcd+cFYmjKKdpocThEdarSmRoMDTDpAiVSVkuTZ/3s8OR+q27YFTGIymHxx+7sLRnXKzI9+IZZxN8ri3o9zAyEbf6KHp4RA2NsKoFyOe3b2u77cv3X9fxveGrTltdMJZlxfGIr9rk7rPjvq8SlYd0dsIFs4a1vf2zrX0YyfHm/eww9/zkso59Zn7uyZxGk06n4AC4/eoVXQOkqUhTk05Kt2BaFXEqiSRVxwkXzBp8JNleFNv+Yth3LEvr9qtXtGxv912XolN49FGnUPANzww+4kgSCEUPkSoFyFBlDQ7QtKXvermWUeQAqLJuU5aw269ewR0zZmY4mvwoPEpm2fOb22677ap04XHCBbMKsRbSyra/mFOa9Y+60LSlJJY9v7ljcAD80QP35TSa4ZKcOem2WFoWVakk4lJ4lEC30AgrW4BIeWnaIsdJO3UJB0inaz+qUnXUmcJDMtOqEkl65qTo6x13zJgZaeG0SlMcTVtEeqRKwRCFKo+Kue2qT/R7CB3N/NyTsauPolcdYXUKEFUeJXDL2efntq88TtWWKQykPYWH9EXUAFHQFJemLSVxy9nndz1le8vZ53PCBTkNqAeGBsPR3754WJ+hbSMefyrTMUl0Co8SyXP6kqdWodGprwKkGBQeJfXy9Z1vtnvGUwdjf2Y/Lk2PExzh9yhA+k/hUULdggPgwMXH/rhUlCApS3BIcSg8SiRKaLRy4OLxTLi7vF/9bkXVR//pbIuIJKLwqImkVUtWNGUpP4WHiCSi8BCRRBQeIpJI1/Aws782s31mtiXUNsHMfmhm24OfpwXtZmZ/ZmY7zGyzmV0ces91Qf/tZhbtHvRynKqdMZFyi1J5fBf4yJC2pcCj7j4DeDR4DfBRYEbwWALcCY2wAb4GzAXmAF9rBo6IlFPX8HD3fwBeHtK8CGj+EYoVwMdD7fd4wzpgvJlNAq4EfujuL7v7K8APGR5IIpHpGo/+S7rm8U533wsQ/DwzaJ8M7A71Gwja2rUPY2ZLzGyjmW08zG8SDk9EstbrBVNr0eYd2oc3ui9399nuPnsUY3o6uCpIuu5RtPUSVQ7llzQ8fhVMRwh+7gvaB4CpoX5TgD0d2iWBCXc/ESsMihYcTSMefypRiCh4iiHpd1seAq4Dbg1+Phhq/4KZraSxOHrI3fea2Rrgj0OLpFcAy5IPW2B4KAy9irSooTGUwqCcuoaHmX0f+BBwhpkN0DhrcivwAzO7AdgFXBt0Xw0sBHYAbwDXA7j7y2b2DWBD0O/r7j50EVZSKktYSDWYe8ulh0Iws9eA5/o9jojOAA70exARlGWcUJ6xlmWc0Hqs73H3iXE/qOhfyX/O3Wf3exBRmNnGMoy1LOOE8oy1LOOE3o5Vl6eLSCIKDxFJpOjhsbzfA4ihLGMtyzihPGMtyzihh2Mt9IKpiBRX0SsPESkohYeIJFLY8DCzj5jZc8G9QZZ2f0emY5lqZo+b2VYze9bMbgraY9/XJKfxjjCzn5rZw8Hr6Wa2PhjnfWY2OmgfE7zeEWyflvM4x5vZKjP7RXBs5xf4mP5B8P/9FjP7vpmdWITj2tf77bh74R7ACOB54CxgNPAz4Nw+jmcScHHw/BRgG3Au8N+ApUH7UuC24PlC4P/Q+ELgPGB9zuP9EvA/gYeD1z8AFgfP/xL4d8HzzwF/GTxfDNyX8zhXAP8meD4aGF/EY0rjG+AvAieFjudni3BcgQ8CFwNbQm2xjiEwAXgh+Hla8Py0rvvO8x9LjAMyH1gTer0MWNbvcYXG8yDwOzSufp0UtE2icVEbwF8Bnwz1H+yXw9im0LhB0+XAw8E/lAPAyKHHFlgDzA+ejwz6WU7jHBf8QtqQ9iIe0+YtJSYEx+lhGveoKcRxBaYNCY9YxxD4JPBXofbj+rV7FHXaEvn+H3kLStCLgPXEv69JHr4F/CHwdvD6dOCgux9pMZbBcQbbDwX983AWsB+4O5hifcfMTqaAx9TdXwJup/E9rr00jtMminlcIcP77YQVNTwi3/8jT2b2DuB+4Ivu/mqnri3aMh+/mX0M2OfumyKOpZ/HeSSNcvtOd78IeJ1jt7NspW9jDdYMFgHTgXcBJ9O45Wa78RTy3y89uN9OWFHDo3D3/zCzUTSC4153fyBojntfk6xdBvyume0EVtKYunyLxu0gm99jCo9lcJzB9lMZfsvJrAwAA+6+Pni9ikaYFO2YAnwYeNHd97v7YeAB4FKKeVwhp/vtFDU8NgAzgtXs0TQWnR7q12DMzIC7gK3u/qehTc37msDw+5p8JljdnkdwX5Osx+nuy9x9irtPo3HMHnP3TwGPA9e0GWdz/NcE/XP5L6S7/xLYbWbvDZoWAD+nYMc0sAuYZ2Zjg38LzbEW7ri22H+UY7gGuMLMTguqrCuCts7yWHBKuAi0kMZZjeeB/9jnsfwWjTJuM/B08FhIYx77KLA9+Dkh6G/AHcHYnwFm92HMH+LY2ZazgCdp3Gflb4ExQfuJwesdwfazch7jhcDG4Lj+Lxor/YU8psB/AX4BbAH+BhhThOMKfJ/GOsxhGhXEDUmOIfD7wXh3ANdH2bcuTxeRRIo6bRGRglN4iEgiCg8RSUThISKJKDxEJBGFh4gkovAQkUT+P9gcbNI5PJfUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results  = pd.DataFrame(results)\n",
    "plt.imshow(results['mask_avg'].iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(mask1, mask2):\n",
    "        \"\"\"\n",
    "        Computes Intersection over Union score for two binary masks.\n",
    "        :param mask1: numpy array\n",
    "        :param mask2: numpy array\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        intersection = np.sum((mask1 + mask2) > 1)\n",
    "        union = np.sum((mask1 + mask2) > 0)\n",
    "\n",
    "        return intersection / float(union)\n",
    "\n",
    "def compute_overlap(mask1, mask2):\n",
    "    intersection = np.sum((mask1 + mask2) > 1)\n",
    "\n",
    "    overlap1 = intersection / float(np.sum(mask1))\n",
    "    overlap2 = intersection / float(np.sum(mask2))\n",
    "    return overlap1, overlap2\n",
    "\n",
    "def sort_mask_by_cells(mask, min_size=50):\n",
    "    \"\"\"\n",
    "    Returns size of each cell.\n",
    "    :param mask:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    cell_num = np.unique(mask)\n",
    "    cell_sizes = [(cell_id, len(np.where(mask == cell_id)[0]))\n",
    "                  for cell_id in cell_num if cell_id != 0]\n",
    "\n",
    "    cell_sizes = [x for x in sorted(\n",
    "        cell_sizes, key=lambda x: x[1], reverse=True) if x[1 > min_size]]\n",
    "\n",
    "    return cell_sizes\n",
    "    \n",
    "def merge_multiple_detections(masks):\n",
    "        \"\"\"\n",
    "\n",
    "        :param masks:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        cell_counter = 0\n",
    "        final_mask = np.zeros(masks[0].shape)\n",
    "\n",
    "        masks_stats = [sort_mask_by_cells(mask) for mask in masks]\n",
    "        cells_left = sum([len(stats) for stats in masks_stats])\n",
    "\n",
    "        while cells_left > 0:\n",
    "            # Choose the biggest cell from available\n",
    "            cells = [stats[0][1] if len(\n",
    "                stats) > 0 else 0 for stats in masks_stats]\n",
    "            reference_mask = cells.index(max(cells))\n",
    "\n",
    "            reference_cell = masks_stats[reference_mask].pop(0)[0]\n",
    "\n",
    "            # Prepare binary mask for cell chosen for comparison\n",
    "            cell_location = np.where(masks[reference_mask] == reference_cell)\n",
    "\n",
    "            cell_mask = np.zeros(final_mask.shape)\n",
    "            cell_mask[cell_location] = 1\n",
    "\n",
    "            masks[reference_mask][cell_location] = 0\n",
    "\n",
    "            # Mask for storing temporary results\n",
    "            tmp_mask = np.zeros(final_mask.shape)\n",
    "            tmp_mask += cell_mask\n",
    "\n",
    "            for mask_id, mask in enumerate(masks):\n",
    "                # For each mask left\n",
    "                if mask_id != reference_mask:\n",
    "                    # # Find overlapping cells on other masks\n",
    "                    overlapping_cells = list(np.unique(mask[cell_location]))\n",
    "\n",
    "                    try:\n",
    "                        overlapping_cells.remove(0)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "                    # # If only one overlapping, check IoU and update tmp mask if high\n",
    "                    if len(overlapping_cells) == 1:\n",
    "                        overlapping_cell_mask = np.zeros(final_mask.shape)\n",
    "                        overlapping_cell_mask[np.where(\n",
    "                            mask == overlapping_cells[0])] = 1\n",
    "\n",
    "                        iou = compute_iou(cell_mask, overlapping_cell_mask)\n",
    "                        if iou >= IOU_THRESHOLD:\n",
    "                            # Add cell to temporary results and remove from stats and mask\n",
    "                            tmp_mask += overlapping_cell_mask\n",
    "                            idx = [i for i, cell in enumerate(\n",
    "                                masks_stats[mask_id]) if cell[0] == overlapping_cells[0]][0]\n",
    "                            masks_stats[mask_id].pop(idx)\n",
    "                            mask[np.where(mask == overlapping_cells[0])] = 0\n",
    "\n",
    "                    # # If more than one overlapping check area overlapping\n",
    "                    elif len(overlapping_cells) > 1:\n",
    "                        overlapping_cell_masks = [\n",
    "                            np.zeros(final_mask.shape) for _ in overlapping_cells]\n",
    "\n",
    "                        for i, cell_id in enumerate(overlapping_cells):\n",
    "                            overlapping_cell_masks[i][np.where(\n",
    "                                mask == cell_id)] = 1\n",
    "\n",
    "                        for cell_id, overlap_mask in zip(overlapping_cells, overlapping_cell_masks):\n",
    "                            overlap_score, _ = compute_overlap(\n",
    "                                overlap_mask, cell_mask)\n",
    "\n",
    "                            if overlap_score >= OVERLAP_THRESHOLD:\n",
    "                                tmp_mask += overlap_mask\n",
    "\n",
    "                                mask[np.where(mask == cell_id)] = 0\n",
    "                                idx = [i for i, cell in enumerate(masks_stats[mask_id])\n",
    "                                       if cell[0] == cell_id][0]\n",
    "                                masks_stats[mask_id].pop(idx)\n",
    "\n",
    "                    # # If none overlapping do nothing\n",
    "\n",
    "            if len(np.unique(tmp_mask)) > 1:\n",
    "                cell_counter += 1\n",
    "                final_mask[np.where(tmp_mask >= MIN_DETECTIONS)] = cell_counter\n",
    "\n",
    "            cells_left = sum([len(stats) for stats in masks_stats])\n",
    "\n",
    "        bin_mask = np.zeros(final_mask.shape)\n",
    "        bin_mask[np.where(final_mask > 0)] = 255\n",
    "        return(final_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (segproj)",
   "language": "python",
   "name": "segproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "328px",
    "width": "719px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
