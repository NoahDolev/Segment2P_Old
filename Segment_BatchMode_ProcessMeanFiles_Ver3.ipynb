{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T13:52:51.949187Z",
     "start_time": "2018-12-15T13:52:29.593597Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# General System stuff\n",
    "import sys\n",
    "import gc\n",
    "import glob\n",
    "import os\n",
    "from os.path import getsize\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "IOU_THRESHOLD = 0.6\n",
    "OVERLAP_THRESHOLD = 0.8\n",
    "MIN_DETECTIONS = 1\n",
    "\n",
    "#--------------------------------------#\n",
    "\n",
    "# Processing stuff\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import operator\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "#--------------------------------------#\n",
    "\n",
    "# Deep learning and GPU stuff\n",
    "from keras import backend as K\n",
    "from numba import cuda\n",
    "import tensorflow as tf \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "import googleapiclient.discovery as discovery\n",
    "\n",
    "sys.path.insert(0, '/home/mestalbet/PythonScripts/Usiigaci/Mask R-CNN')\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import utils\n",
    "from train import cellConfig\n",
    "\n",
    "#--------------------------------------#\n",
    "\n",
    "# Image Stuff\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tifffile import imsave,imread\n",
    "from skimage import exposure\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import io as skio\n",
    "from skimage import util\n",
    "\n",
    "#--------------------------------------#\n",
    "\n",
    "# File Handling\n",
    "import datetime\n",
    "import time\n",
    "from glob import glob\n",
    "import csv\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "\n",
    "#--------------------------------------#\n",
    "\n",
    "# GUI\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "#--------------------------------------#\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import colorsys\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import plotly.offline as offline\n",
    "plotly.offline.init_notebook_mode(connected=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outpath = \"/home/mestalbet/PythonScripts/Results_LiorImages/\"\n",
    "data_dir = \"gs://segproj/PythonScripts/Results_LiorImages/inference/pngs/\"\n",
    "# data_dir = os.path.join(outpath,\"inference/\")\n",
    "model_path_1 = \"/home/mestalbet/PythonScripts/out/latest/mask_rcnn_cell_0100.h5\"\n",
    "model_path_2 = \"/home/mestalbet/PythonScripts/out/latest/mask_rcnn_cell_0198.h5\"\n",
    "model_path_3 = \"/home/mestalbet/PythonScripts/out/latest/mask_rcnn_cell_0199.h5\"\n",
    "model_path_4 = \"/home/mestalbet/PythonScripts/out/latest/mask_rcnn_cell_0200.h5\"\n",
    "model_list = [model_path_1, model_path_2, model_path_3, model_path_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Configuration class\n",
    "chunksize = 1\n",
    "class CellInferenceConfig(cellConfig):\n",
    "        # Set batch size to 1 to run one image at a time\n",
    "        GPU_COUNT = 1\n",
    "        IMAGES_PER_GPU = chunksize\n",
    "        # Don't resize imager for inferencing\n",
    "        IMAGE_RESIZE_MODE = \"pad64\"\n",
    "        # Non-max suppression threshold to filter RPN proposals.\n",
    "        # You can increase this during training to generate more propsals.\n",
    "        RPN_NMS_THRESHOLD = 0.7\n",
    "        # define the folder path to data for prediction\n",
    "        global data_dir\n",
    "        all_files = []\n",
    "        sub_directory = []\n",
    "        for root, dirs, files in os.walk(data_dir):\n",
    "            for file in files:\n",
    "                relativePath = os.path.relpath(root, data_dir)\n",
    "                if relativePath == \".\":\n",
    "                    relativePath = \"\"\n",
    "                all_files.append(\n",
    "                    (relativePath.count(os.path.sep), relativePath, file))\n",
    "        all_files.sort(reverse=True)\n",
    "        for (count, folder), files in groupby(all_files, itemgetter(0, 1)):\n",
    "            sub_directory.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Setup Path Iterator ######\n",
    "\n",
    "#Delete old models\n",
    "# os.system(\"rm /home/mestalbet/bucket/PythonScripts/savedmodel/ver* -r\") \n",
    "\n",
    "dirs = os.listdir(\"/home/mestalbet/bucket/PythonScripts/savedmodel/\") \n",
    "vernum = [int(d[-1]) for d in dirs]\n",
    "if not vernum:\n",
    "    vernum = 0\n",
    "else:\n",
    "    vernum = np.max(vernum)\n",
    "model_dirpath = \"/home/mestalbet/bucket/PythonScripts/savedmodel/ver%d\" % (vernum+1)\n",
    "if not os.path.exists(model_dirpath):\n",
    "    os.makedirs(model_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Save Each Model (different checkpoints)#####\n",
    "for modelpath in model_list: \n",
    "    # Load model\n",
    "    K.clear_session()\n",
    "    model = modellib.MaskRCNN(\n",
    "        mode=\"inference\", config=CellInferenceConfig(), model_dir=data_dir)\n",
    "    # Load weights from H5\n",
    "    model.load_weights(modelpath, by_name=True)\n",
    "    sess = K.get_session()\n",
    "\n",
    "    outputs = [output.name for output in model.keras_model.outputs]\n",
    "    outs = {str(o):sess.graph.get_tensor_by_name(o) for o in outputs}\n",
    "    output_names_all = [output.split(':')[0] for output in outputs]\n",
    "    \n",
    "    # Save model\n",
    "    tf.saved_model.simple_save(sess,\n",
    "                               model_dirpath+\"/savedmodel_%s/\" % modelpath.split('/')[-1][-7:-3],\n",
    "                               inputs={'input_image':model.keras_model.inputs[0], \n",
    "                                       'input_image_meta':model.keras_model.inputs[1],\n",
    "                                       'input_anchors':model.keras_model.inputs[2]},\n",
    "                               outputs=outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelpath = model_list[0]\n",
    "# K.clear_session()\n",
    "# model = modellib.MaskRCNN(mode=\"inference\", config=CellInferenceConfig(), model_dir=data_dir)\n",
    "# # Load weights from H5\n",
    "# model.load_weights(modelpath, by_name=True)\n",
    "# model = model.keras_model\n",
    "# sess = K.get_session()\n",
    "\n",
    "# outputs = [output.name for output in model.outputs]\n",
    "# outs = {str(o):sess.graph.get_tensor_by_name(o) for o in outputs}\n",
    "\n",
    "# outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mestalbet/anaconda3/envs/segproj/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "predict_instance_json = \"/home/mestalbet/bucket/PythonScripts/submit_data/inputs.json\"\n",
    "bucketpath = \"gs://segproj/PythonScripts/Results_LiorImages/inference/\"\n",
    "os.system(\"rm %s\" % (predict_instance_json))\n",
    "config=CellInferenceConfig()\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=data_dir)\n",
    "model.load_weights(model_path_1, by_name=True)\n",
    "\n",
    "class ImageDataset(utils.Dataset):\n",
    "    def load_images(self, dataset_dir):\n",
    "        \"\"\"\n",
    "        Loads dataset images.\n",
    "        :param dataset_dir: string, path to dataset directory.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.add_class(\"cell\", 1, \"cell\")\n",
    "\n",
    "        image_ids = [fn for fn in os.listdir(dataset_dir)\n",
    "                     if any(fn.endswith(ext) for ext in ['tif', \"png\"])]\n",
    "\n",
    "        for image_id in image_ids:\n",
    "            self.add_image(\n",
    "                'cell',\n",
    "                image_id=os.path.splitext(image_id)[0],\n",
    "                path=os.path.join(dataset_dir, image_id)\n",
    "            )\n",
    "dataset = ImageDataset()\n",
    "dataset.load_images(\"/home/mestalbet/PythonScripts/Results_LiorImages/inference/\")\n",
    "dataset.prepare()\n",
    "with open(predict_instance_json, \"w+\") as fp:\n",
    "    for image_id in dataset.image_ids[:100]:\n",
    "        image = dataset.load_image(image_id)\n",
    "        active_class_ids = np.zeros([dataset.num_classes], dtype=np.int32)\n",
    "        source_class_ids = dataset.source_class_ids[dataset.image_info[image_id][\"source\"]]\n",
    "        active_class_ids[source_class_ids] = 1\n",
    "        img, window, scale, padding, crop = utils.resize_image(\n",
    "                image,\n",
    "                min_dim=config.IMAGE_MIN_DIM,\n",
    "                min_scale=config.IMAGE_MIN_SCALE,\n",
    "                max_dim=config.IMAGE_MAX_DIM,\n",
    "                mode=config.IMAGE_RESIZE_MODE)\n",
    "        meta = np.array(\n",
    "            [image_id] +                  # size=1\n",
    "            list(image.shape) +           # size=3\n",
    "            list(img.shape) +             # size=3\n",
    "            list(window) +                # size=4 (y1, x1, y2, x2) in image cooredinates\n",
    "            [scale] +                     # size=1\n",
    "            list(active_class_ids)        # size=num_classes\n",
    "            )\n",
    "        anchors = model.get_anchors(image.shape)\n",
    "        json_data = {'input_image':image.tolist(),\n",
    "                     'input_image_meta':meta.tolist(),\n",
    "                     'input_anchors':anchors.tolist()} #,'key':int(image_id)\n",
    "        jline = json.dumps(json_data) + \"\\n\"\n",
    "        fp.write(jline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mestalbet/anaconda3/envs/segproj/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning:\n",
      "\n",
      "Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "\n",
      "/home/mestalbet/anaconda3/envs/segproj/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning:\n",
      "\n",
      "Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "\n",
      "/home/mestalbet/anaconda3/envs/segproj/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning:\n",
      "\n",
      "Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "\n",
      "/home/mestalbet/anaconda3/envs/segproj/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning:\n",
      "\n",
      "Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Submit job to cloud\n",
    "# ------------------------------------------#\n",
    "# Define batch job submission vfunction\n",
    "def make_batch_job_body(project_name, input_paths, output_path,\n",
    "                        model_name, region, data_format='JSON',\n",
    "                        version_name=None, max_worker_count=None,\n",
    "                        runtime_version=None):\n",
    "\n",
    "    project_id = 'projects/{}'.format(project_name)\n",
    "    model_id = '{}/models/{}'.format(project_id, model_name)\n",
    "    if version_name:\n",
    "        version_id = '{}/versions/{}'.format(model_id, version_name)\n",
    "\n",
    "    # Make a jobName of the format \"model_name_batch_predict_YYYYMMDD_HHMMSS\"\n",
    "    timestamp = time.strftime('%Y%m%d_%H%M%S', time.gmtime())\n",
    "\n",
    "    # Make sure the project name is formatted correctly to work as the basis\n",
    "    # of a valid job name.\n",
    "    clean_project_name = re.sub(r'\\W+', '_', project_name)\n",
    "\n",
    "    job_id = '{}_{}_{}'.format(clean_project_name, model_name,\n",
    "                           timestamp)\n",
    "\n",
    "    # Start building the request dictionary with required information.\n",
    "    body = {'jobId': job_id,\n",
    "            'predictionInput': {\n",
    "                'dataFormat': data_format,\n",
    "                'inputPaths': input_paths,\n",
    "                'outputPath': output_path,\n",
    "                'region': region}}\n",
    "\n",
    "    # Use the version if present, the model (its default version) if not.\n",
    "    if version_name:\n",
    "        body['predictionInput']['versionName'] = version_id\n",
    "    else:\n",
    "        body['predictionInput']['modelName'] = model_id\n",
    "\n",
    "    # Only include a maximum number of workers or a runtime version if specified.\n",
    "    # Otherwise let the service use its defaults.\n",
    "    if max_worker_count:\n",
    "        body['predictionInput']['maxWorkerCount'] = max_worker_count\n",
    "\n",
    "    if runtime_version:\n",
    "        body['predictionInput']['runtimeVersion'] = runtime_version\n",
    "\n",
    "    return body\n",
    "\n",
    "# Project definitions\n",
    "project_name = \"divine-builder-142611\"\n",
    "credentials_path = \"/home/mestalbet/bucket/PythonScripts/Segmentation Project-a5a157bd9401.json\"\n",
    "project_id = 'projects/{}'.format(project_name)\n",
    "input_paths = \"gs://segproj/PythonScripts/submit_data/\"\n",
    "output_path = \"gs://segproj/PythonScripts/cloud_output/\"\n",
    "model_name = \"segmentation\"\n",
    "region = \"us-central1\"\n",
    "\n",
    "# Submit job\n",
    "version_names = ['Model0100_Ver1_0','Model0198_Ver1_0','Model0199_Ver1_0','Model0200_Ver1_0']\n",
    "for vn in version_names:\n",
    "    op = os.path.join(output_path,vn)\n",
    "    if not os.path.exists(op):\n",
    "        os.makedirs(op)\n",
    "\n",
    "    dirs = os.listdir(op) \n",
    "    vernum = [int(d[-1]) for d in dirs]\n",
    "    if not vernum:\n",
    "        vernum = 0\n",
    "    else:\n",
    "        vernum = np.max(vernum)\n",
    "    op = os.path.join(op, \"run_%d\" % (vernum+1))\n",
    "    if not os.path.exists(op):\n",
    "        os.makedirs(op)\n",
    "        \n",
    "    batch_predict_body = make_batch_job_body(project_name, input_paths, op,\n",
    "                                             model_name, region, data_format='JSON',\n",
    "                                             version_name=vn, max_worker_count=None,\n",
    "                                             runtime_version=None)\n",
    "    ml = discovery.build('ml', 'v1')\n",
    "    request = ml.projects().jobs().create(parent=project_id,body=batch_predict_body)\n",
    "    response = request.execute()\n",
    "\n",
    "# developerKey=\"AIzaSyCmugrkm9rIUpn8AnAKxX8KaKZJU5Qjz6Q\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = model_list[0]\n",
    "K.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=CellInferenceConfig(), model_dir=data_dir)\n",
    "\n",
    "respath = \"/home/mestalbet/bucket/PythonScripts/cloud_output/\"\n",
    "resfiles = glob(respath+'prediction.results*')\n",
    "resfiles = [r for r in resfiles if getsize(r)>0]\n",
    "ishape = (1024, 1024, 3)\n",
    "mshape = (2048, 2048, 3)\n",
    "window = np.array([   0,    0, 2048, 2048])\n",
    "final_masks=[]\n",
    "for resfile in resfiles:\n",
    "    json_data=open(resfile).read()\n",
    "    data = json.loads(json_data)\n",
    "    _, _, _, fm = model.unmold_detections(\n",
    "                                np.asarray(data['mrcnn_detection/Reshape_1:0']), \n",
    "                                np.asarray(data['mrcnn_mask/Reshape_1:0']),\n",
    "                                ishape, mshape, window)\n",
    "    if (fm.shape[0]!=1024 or fm.shape[2]<1):\n",
    "        print(\"Image Output Size Error\")\n",
    "    else: \n",
    "        final_masks.append(np.argmax(fm,2))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_1/prediction.results-00001-of-00005\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00002-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00009-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00015-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00022-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00025-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00037-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00046-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00053-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00055-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00058-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00060-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00069-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00070-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00074-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00076-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00083-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00085-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00088-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00089-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00091-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0100_Ver1_0/run_2/prediction.results-00099-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0198_Ver1_0/run_2/prediction.results-00031-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0198_Ver1_0/run_2/prediction.results-00077-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0199_Ver1_0/run_2/prediction.results-00000-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0199_Ver1_0/run_2/prediction.results-00002-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0199_Ver1_0/run_2/prediction.results-00015-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0199_Ver1_0/run_2/prediction.results-00080-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0200_Ver1_0/run_2/prediction.results-00011-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0200_Ver1_0/run_2/prediction.results-00044-of-00100\n",
      "Image Output Size Error: /home/mestalbet/bucket/PythonScripts/cloud_output/Model0200_Ver1_0/run_2/prediction.results-00064-of-00100\n"
     ]
    }
   ],
   "source": [
    "respath = \"/home/mestalbet/bucket/PythonScripts/cloud_output/\"\n",
    "modelpath = model_list[0]\n",
    "K.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=CellInferenceConfig(), model_dir=data_dir)\n",
    "\n",
    "model_cp=[]\n",
    "model_ver=[]\n",
    "image_num=[] \n",
    "run_num=[]\n",
    "mask=[]\n",
    "ishape = (1024, 1024, 3)\n",
    "mshape = (2048, 2048, 3)\n",
    "window = np.array([   0,    0, 2048, 2048])\n",
    "for (dirpath, dirnames, filenames) in os.walk(respath):\n",
    "    for file in filenames:\n",
    "        resfile = os.path.join(dirpath, file)\n",
    "        if ('prediction.results' in resfile and getsize(resfile)>0):\n",
    "            json_data=open(resfile).read()\n",
    "            data = json.loads(json_data)\n",
    "            _, _, _, fm = model.unmold_detections(\n",
    "                                        np.asarray(data['mrcnn_detection/Reshape_1:0']), \n",
    "                                        np.asarray(data['mrcnn_mask/Reshape_1:0']),\n",
    "                                        ishape, mshape, window)\n",
    "            if (fm.shape[0]!=1024 or fm.shape[2]<1):\n",
    "                print(\"Image Output Size Error: %s\" % (resfile))\n",
    "            else:\n",
    "                model_cp.append(dirpath.split('/')[-2].split('_')[0])\n",
    "                model_ver.append(dirpath.split('/')[-2].split('_')[1])\n",
    "                image_num.append(int(file.split('-')[1]))\n",
    "                run_num.append(int(dirpath.split('/')[-1].split('_')[-1]))\n",
    "                mask.append(np.argmax(fm,2))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_cp</th>\n",
       "      <th>model_ver</th>\n",
       "      <th>image_num</th>\n",
       "      <th>run_num</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model0100</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model0100</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model0100</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model0100</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model0100</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Model0100</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Model0100</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Model0100</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Model0100</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Model0100</td>\n",
       "      <td>Ver1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_cp model_ver  image_num  run_num  \\\n",
       "0  Model0100      Ver1          0        1   \n",
       "1  Model0100      Ver1          2        1   \n",
       "2  Model0100      Ver1          3        1   \n",
       "3  Model0100      Ver1          4        1   \n",
       "4  Model0100      Ver1          0        2   \n",
       "5  Model0100      Ver1          1        2   \n",
       "6  Model0100      Ver1          3        2   \n",
       "7  Model0100      Ver1          4        2   \n",
       "8  Model0100      Ver1          5        2   \n",
       "9  Model0100      Ver1          6        2   \n",
       "\n",
       "                                                mask  \n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "5  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "6  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "7  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "8  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "9  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'model_cp':model_cp,\n",
    "                   'model_ver':model_ver,\n",
    "                   'image_num':image_num, \n",
    "                   'run_num':run_num,\n",
    "                   'mask':final_masks})\n",
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "no results",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-2fc46ceba76e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_grouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_cp'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'model_ver'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'image_num'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'run_num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/segproj/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4654\u001b[0m         axis=''))\n\u001b[1;32m   4655\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4656\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataFrameGroupBy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4658\u001b[0m     \u001b[0magg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/segproj/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4086\u001b[0m         \u001b[0m_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_level'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4087\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4088\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4089\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/segproj/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_aggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m             return self._aggregate_multiple_funcs(arg,\n\u001b[1;32m    550\u001b[0m                                                   \u001b[0m_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_level\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                                                   _axis=_axis), None\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/segproj/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_aggregate_multiple_funcs\u001b[0;34m(self, arg, _level, _axis)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;31m# if we are empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: no results"
     ]
    }
   ],
   "source": [
    "df_grouped = df.groupby(['model_cp','model_ver','image_num','run_num']).agg([np.sum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (segproj)",
   "language": "python",
   "name": "segproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "30",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "328px",
    "width": "719px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
